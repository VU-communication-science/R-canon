{
  "hash": "1af4c00dbb076edd9a313a6d93bc09fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Pipes\"\norder: 5\n---\n\n\n\n\n\n\n# Working with Pipes\n\nIf you look at the code above, you notice that the result of each function is stored as an object, \nand that this object is used as the first argument for the next function.\nMoreover, we don't really care about this temporary object, we only care about the final summary table. \n\nThis is a very common usage pattern, and it can be seen as a *pipeline* of functions, where the output of each function is the input for the next function.\nBecause this is so common, tidyverse offers a more convenient way of writing the code above using the pipeline operator `%>%`.\nIn sort, whenever you write `f(a, x)` you can replace it by `a %>% f(x)`. If you then want to use the output of `f(a, x)` for a second function,\nyou can just add it to the pipe: `a %>% f(x) %>% f2(y)` is equivalent to `f2(f(a,x), y)`, or more readable, `b=f(a,x); f2(b, y)`\n\nPut simply, pipes take the output of a function, and directly use that output as the input for the `.data` argument in the next function. As you have seen, all the `dplyr` functions that we discussed have in common that the first argument is a *tibble*, and all functions return a *tibble*. This is intentional, and allows us to pipe all the functions together. \n\nThis seems a bit abstract, but consider the code below, which is a collection of statements from above:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# d <- read_csv(url)\n# d <- filter(d, Question == 'age-21')\n# d <- mutate(d, party_diff = abs(`Republican Support` - `Democratic Support`))\n# d <- select(d, Question, Pollster, party_diff)\n# arrange(d, -party_diff)\n```\n:::\n\n\n\n\n\nTo recap, this reads the csv, filters by question, computes the difference, drops other variables, and sorts.\nSince the output of each function is the input of the next, we can also write this as a single pipeline:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read_csv(url) %>% \n#   filter(Question == 'age-21') %>% \n#   mutate(party_diff = abs(`Republican Support` - `Democratic Support`)) %>%\n#   select(Question, Pollster, party_diff) %>% \n#   arrange(-party_diff)\n```\n:::\n\n\n\n\n\nThe nice thing about pipes is that it makes it really clear what you are doing. Also, it doesn't require making many intermediate objects (such as `ds`). If applied right, piping allows you to make nicely contained pieces of code to perform specific parts of your analysis from raw input straight to results, including statistical modeling or visualization. It usually makes sense to have each \"step\" in the pipeline in its own line. This way, we can easily read the code line by line\n\nOf course, you probably don't want to replace your whole script with a single pipe, and often it is nice to store intermediate values.\nFor example, you might want to download, clean, and subset a data set before doing multiple analyses with it.\nIn that case, you probably want to store the result of downloading, cleaning, and subsetting as a variable, and use that in your analyses.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}