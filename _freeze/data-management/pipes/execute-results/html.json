{
  "hash": "9ed047d938b9efc5595d1f0ceacea714",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using the pipe notation\"\nsubtitle: \"How to make your code more readable\"\norder: 5\n---\n\n\n\n\n\n\n# Working with Pipes\n\nIn the previous sections you learned several data management techniques.\nIn practise, you will often apply multiple of these techniques in succession to clean and prepare data.\nFor example, the following code reads a csv file, filters rows, computes a new variable, selects columns, and sorts the data:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\npractice_data = read_csv(\"https://tinyurl.com/R-practice-data\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 600 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): np_subscription, experiment_group\ndbl (15): id, age, news consumption, trust_t1, trust_t2, trust_t1_item1, tru...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npractice_data = select(practice_data, age, experiment_group, trust_t1)\npractice_data = filter(practice_data, age >= 18)\npractice_data = arrange(practice_data, trust_t1)\n```\n:::\n\n\n\n\n\nThis code works fine, but it is a bit cumbersome to read.\nFor each step, we need to provide `practice_data` as input, and also assign the output to `practice_data` to overwrite it.\nCurrently this is just three times, but \n\n\n\nIf syou look at the code above, you notice that the result of each function is stored as an object, \nand that this object is used as the first argument for the next function.\nMoreover, we don't really care about this temporary object, we only care about the final summary table. \n\nThis is a very common usage pattern, and it can be seen as a *pipeline* of functions, where the output of each function is the input for the next function.\nBecause this is so common, tidyverse offers a more convenient way of writing the code above using the pipeline operator `%>%`.\nIn sort, whenever you write `f(a, x)` you can replace it by `a %>% f(x)`. If you then want to use the output of `f(a, x)` for a second function,\nyou can just add it to the pipe: `a %>% f(x) %>% f2(y)` is equivalent to `f2(f(a,x), y)`, or more readable, `b=f(a,x); f2(b, y)`\n\nPut simply, pipes take the output of a function, and directly use that output as the input for the `.data` argument in the next function. As you have seen, all the `dplyr` functions that we discussed have in common that the first argument is a *tibble*, and all functions return a *tibble*. This is intentional, and allows us to pipe all the functions together. \n\nThis seems a bit abstract, but consider the code below, which is a collection of statements from above:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# d <- read_csv(url)\n# d <- filter(d, Question == 'age-21')\n# d <- mutate(d, party_diff = abs(`Republican Support` - `Democratic Support`))\n# d <- select(d, Question, Pollster, party_diff)\n# arrange(d, -party_diff)\n```\n:::\n\n\n\n\n\nTo recap, this reads the csv, filters by question, computes the difference, drops other variables, and sorts.\nSince the output of each function is the input of the next, we can also write this as a single pipeline:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read_csv(url) %>% \n#   filter(Question == 'age-21') %>% \n#   mutate(party_diff = abs(`Republican Support` - `Democratic Support`)) %>%\n#   select(Question, Pollster, party_diff) %>% \n#   arrange(-party_diff)\n```\n:::\n\n\n\n\n\nThe nice thing about pipes is that it makes it really clear what you are doing. Also, it doesn't require making many intermediate objects (such as `ds`). If applied right, piping allows you to make nicely contained pieces of code to perform specific parts of your analysis from raw input straight to results, including statistical modeling or visualization. It usually makes sense to have each \"step\" in the pipeline in its own line. This way, we can easily read the code line by line\n\nOf course, you probably don't want to replace your whole script with a single pipe, and often it is nice to store intermediate values.\nFor example, you might want to download, clean, and subset a data set before doing multiple analyses with it.\nIn that case, you probably want to store the result of downloading, cleaning, and subsetting as a variable, and use that in your analyses.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}