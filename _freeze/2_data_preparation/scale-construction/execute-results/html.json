{
  "hash": "b5dfe45e02fadbd5de5e9864e91d02b1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Scale construction\nsubtitle: How to create and validate scales\norder: 2\n---\n\n\n\n\n\n# What is a scale?\n\nA scale is a composite measure that combines multiple items into a single score.\nFor example, in order to measure the complex construct \"happiness\", you could ask people multiple questions related to happiness, such as \"How often do you feel happy?\", \"How satisfied are you with your life?\", and \"How often do you feel joy?\".\n\nThe idea is that by combining multiple items into a single score, you can get a more reliable and valid measure of the underlying construct.\nIf we would just ask people the single question \"How happy are you?\", we might not get a very accurate measure of their happiness, because happiness is a complex and multi-faceted construct.\nBy breaking it down into a multi-item scale, we can get a more nuanced and accurate measure.\n\nIf you've ever taken a survey, you've probably encountered scales before.\nFor example, you might have been asked to rate your agreement with a series of statements on a scale from 1 to 5, where 1 means \"strongly disagree\" and 5 means \"strongly agree\".\nThis is also called a **Likert scale**, and it's a common way to gather data on multiple items, with the goal of combining them into a single score for a complex construct.\n\nYou will also hear scales referred to as **latent variables**.\nThe word **latent** means hidden or concealed, and it refers here to the fact that the construct we are trying to measure is not directly observable.\nWe can only measure it propertly by looking at multiple observable indicators (items) that are related to the construct.\n\n## How to create a scale {#create-scale}\n\nTo create a scale, we combine multiple columns in your data (i.e. the variables for the scale items) into a single score.\nFor instance, by taking the average of the values in these columns.\nHowever, before we can do that, we need to make sure that the scale is reliable and valid.\nThis requires a few steps:\n\n### 1. Choose the items based on theory\n\nFirst, you need to think carefully about which items to include in your scale, and this needs to be grounded in theory.\nThere might also already be existing scales that you can use.\n\nFor example, in our [practice data](../data-management/index.qmd#practice-data) we have a construct called \"trust in journalism\", which we measure with five items, based on the items proposed by @stromback20. Participants were asked to rate their agreement with the following items on a scale from 1 to 10:\n\n1. Journalists are fair when covering the news\n2. Journalists are unbiased when covering the news\n3. Journalists do not tell the whole story when covering the news\n4. Journalists are accurate when covering the news\n5. Journalists separate facts from opinion when covering the news\n\nNote that **item 3 is inversed**, so that higher values indicate lower trust.\nKeep this in mind, because to create the scale we \n\n### 2. Inspect your data\n\nOnce you have collected your data, always check whether everything is in order. \nIn the [Inspect and clean](../data-management/index.qmd#inspect-and-clean) chapter we looked at how to do this.\nHere we just use the `dfSummary` function from the `summarytools` package to get a quick overview of our data.\n\nFirst though, let's load our data and select the columns that we're interested in. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nd = read_csv('https://tinyurl.com/R-practice-data')\n```\n:::\n\n\n\n\nIn the practice data we have two scales: `trust_t1` and `trust_t2`, with each having five items (`trust_t1_item1` to `trust_t1_item5` and `trust_t2_item1` to `trust_t2_item5`).\nFor this tutorial we'll just focus on `trust_t1`.\nThe following code selects the five items for `trust_t1`, and then uses the `dfSummary` function to get a summary of these columns.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(summarytools)\n\nd |> \n    select(trust_t1_item1:trust_t1_item5) |> \n    dfSummary() |>\n    view()\n```\n:::\n\n\n\n\nThis looks good. \nThere are no missing values, all values are within the expected range (1-10), and the distributions look reasonable.\n\n### 3. Look at the correlations\n\nThe idea behind a scale is that the items are related to each other, because they all measure the same underlying construct.\nA good way to check this is by looking at the correlations between the items.\n\nFor this we'll be using the `sjPlot` package, which has a function `tab_corr` (tabulate correlations) that creates a nice table with the correlations between all columns in a data frame. \nWe again use this on the five items for `trust_t1`.\nIn `tab_corr` we also set `p.numeric=TRUE` to show the p-values for the correlations as numbers (instead of stars).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sjPlot)\nd |> \n    select(trust_t1_item1:trust_t1_item5) |> \n    tab_corr(p.numeric=TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">&nbsp;</th>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">trust_t1_item1</th>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">trust_t1_item2</th>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">trust_t1_item3</th>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">trust_t1_item4</th>\n<th style=\"font-style:italic; font-weight:normal; border-top:double black; border-bottom:1px solid black; padding:0.2cm;\">trust_t1_item5</th>\n</tr>\n<tr>\n<td style=\"font-style:italic;\">trust_t1_item1</td>\n<td style=\"padding:0.2cm; text-align:center;\">&nbsp;</td>\n<td style=\"padding:0.2cm; text-align:center;\">0.268<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.730<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.724<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.848<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n</tr>\n<tr>\n<td style=\"font-style:italic;\">trust_t1_item2</td>\n<td style=\"padding:0.2cm; text-align:center;\">0.268<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">&nbsp;</td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.273<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.252<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.289<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n</tr>\n<tr>\n<td style=\"font-style:italic;\">trust_t1_item3</td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.730<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.273<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">&nbsp;</td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.673<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.764<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n</tr>\n<tr>\n<td style=\"font-style:italic;\">trust_t1_item4</td>\n<td style=\"padding:0.2cm; text-align:center;\">0.724<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.252<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.673<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">&nbsp;</td>\n<td style=\"padding:0.2cm; text-align:center;\">0.753<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n</tr>\n<tr>\n<td style=\"font-style:italic;\">trust_t1_item5</td>\n<td style=\"padding:0.2cm; text-align:center;\">0.848<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.289<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">-0.764<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">0.753<br><span style=\"font-style:italic;\">(&lt;.001)</span></td>\n<td style=\"padding:0.2cm; text-align:center;\">&nbsp;</td>\n</tr>\n<tr>\n<td colspan=\"6\" style=\"border-bottom:double black; border-top:1px solid black; font-style:italic; font-size:0.9em; text-align:right;\">Computed correlation used pearson-method with listwise-deletion.</td>\n</tr>\n \n</table>\n`````\n:::\n:::\n\n\n\n\nHere we see that the correlations between the items is mostly quite strong, and all significant at the 0.001 level.\nThe only notable exception in terms of strength is that the correlations of `item2` to the other items is much lower.\nThis suggests that our items indeed measure are common underlying construct, but `item2` (about *bias*) might measure a somewhat different aspect of trust in journalism.\n\nOne **very important thing** to notice is that the correlation of `trust_t1_item3` with the other items is **negative**! \nSo when the score on `trust_t1_item3` goes up, the scores on the other items tend to go down.\nThis makes complete sense if we remember that `trust_t1_item3` is inversed, so that higher values indicate lower trust.\n\n\n::: {.callout-note title=\"Factor analysis\" collapse=\"true\"}\n\nAnother common way to check whether the items in your scale are related is by using **factor analysis**.\nThis is a statistical technique that can help you identify the underlying factors that explain the correlations between the items.\nWe'll cover factor analysis in a later tutorial.\n\n:::\n\n### 4. Invert items if necessary\n\nIn the correlation analysis we saw that the third item (`trust_t1_item3`) is negatively correlated with the other items.\nThis is all according to plan, since we inversed the scale for this item.\nBut to create a single construct, we need to make sure that all items have the same directionality.\nSo we need to invert the values for `trust_t1_item3`. \n\nSince we have a scale from 1 to 10, we can inverse the value by subtracking it from `11` (11 - 1 = 10, 11 - 2 = 9, ..., 11 - 10 = 1).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n    mutate(trust_t1_item3_inv = 11 - trust_t1_item3)\n```\n:::\n\n\n\n\nNotice that we **do not** overwrite the original column, but create a new column `trust_t1_item3_inv` (inversed). \nOverwriting the original column is possible, but dangerous and not transparent. \nCreating a new column prevents you from accidentally running the inversion multiple times, and messing up your analysis.\n\n::: {.callout-note title=\"General formula for inversing\" collapse=\"true\"}\n\nSince we had a scale from 1 to 10, we could invert the values by subtracting from 11.\nSimilarly, if you have a scale from 1 to 7, you could invert the values by subtracting from 8.\nSo for any scale starting from 1, the formula you can use is:\n\n$$ \\text{new value} = \\text{max value} + 1 - \\text{old value} $$\n\nHowever, if your scale does not start from 1, this doesn't work!\n(try it out for a scale from 0 to 10, and you'll see why).\nThe more general formula therefore is:\n\n$$ \\text{new value} = \\text{max value} + \\text{min value} - \\text{old value} $$\n\nNote that in this case you need to use the minimum and maximum **possible** values of your scale, and NOT the actual minimum and maximum values in your data!\nSo if your scale goes from 1 to 7, you would use 1 and 7 in the formula, even if the minimum and maximum values in your data are 1.5 and 6.5.\n\n:::\n\n### 5. Calculate the reliability\n\nThe reliability of a scale is a measure of how consistent the items in the scale are.\nThere are different ways to calculate reliability, but one of the most common is **Cronbach's alpha**.\n\nCronbach's alpha ranges from 0 to 1, where higher values indicate higher reliability.\nA common rule of thumb is that a value of 0.7 or higher is acceptable, but this can vary depending on the context.\nAs with any *rule of thumb*, don't blindly follow it, but think about what makes sense in your specific situation.\n\nTo calculate Cronbach's alpha, we can use the `psych` package, which has a function `alpha` that calculates the alpha for the columns on an input data frame.\nSo we'll do the same thing as above, but note that this time our select statement looks different, because we need to include the inversed item.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\n\nd |> \n    select(trust_t1_item1,  \n           trust_t1_item2, \n           trust_t1_item3_inv, \n           trust_t1_item4, \n           trust_t1_item5) |> \n    alpha()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nReliability analysis   \nCall: alpha(x = select(d, trust_t1_item1, trust_t1_item2, trust_t1_item3_inv, \n    trust_t1_item4, trust_t1_item5))\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.85      0.86    0.87      0.56 6.3 0.01  3.9 0.99      0.7\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.83  0.85  0.87\nDuhachek  0.83  0.85  0.87\n\n Reliability if an item is dropped:\n                   raw_alpha std.alpha G6(smc) average_r  S/N alpha se  var.r\ntrust_t1_item1          0.78      0.80    0.80      0.50  4.0   0.0153 0.0642\ntrust_t1_item2          0.92      0.92    0.90      0.75 11.9   0.0052 0.0034\ntrust_t1_item3_inv      0.79      0.81    0.82      0.52  4.4   0.0151 0.0785\ntrust_t1_item4          0.80      0.82    0.83      0.53  4.5   0.0143 0.0778\ntrust_t1_item5          0.77      0.79    0.78      0.49  3.8   0.0162 0.0598\n                   med.r\ntrust_t1_item1      0.48\ntrust_t1_item2      0.74\ntrust_t1_item3_inv  0.51\ntrust_t1_item4      0.51\ntrust_t1_item5      0.47\n\n Item statistics \n                     n raw.r std.r r.cor r.drop mean  sd\ntrust_t1_item1     600  0.88  0.89  0.89   0.80  4.1 1.1\ntrust_t1_item2     600  0.56  0.52  0.31   0.30  2.7 1.5\ntrust_t1_item3_inv 600  0.85  0.86  0.82   0.75  4.3 1.3\ntrust_t1_item4     600  0.83  0.85  0.80   0.74  3.7 1.1\ntrust_t1_item5     600  0.90  0.91  0.92   0.83  4.6 1.2\n\nNon missing response frequency for each item\n                      1    2    3    4    5    6    7 8 9 miss\ntrust_t1_item1     0.01 0.07 0.22 0.33 0.27 0.10 0.01 0 0    0\ntrust_t1_item2     0.26 0.23 0.22 0.14 0.10 0.03 0.00 0 0    0\ntrust_t1_item3_inv 0.01 0.06 0.20 0.26 0.28 0.13 0.05 0 0    0\ntrust_t1_item4     0.02 0.12 0.29 0.34 0.18 0.04 0.00 0 0    0\ntrust_t1_item5     0.00 0.03 0.15 0.25 0.32 0.18 0.06 0 0    0\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note title=\"Cronbach's alpha with 3 digits\" collapse=\"true\"}\n\nBy default, `alpha` only shows two digits for Cronbach's alpha.\nIf you want to see more digits, you can use the `print` function with the `digits` argument.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n    select(trust_t1_item1, trust_t1_item2, trust_t1_item3_inv, trust_t1_item4, trust_t1_item5) |> \n    alpha() |>\n    print(digits=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nReliability analysis   \nCall: alpha(x = select(d, trust_t1_item1, trust_t1_item2, trust_t1_item3_inv, \n    trust_t1_item4, trust_t1_item5))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean    sd median_r\n     0.848     0.863   0.867     0.557 6.3 0.0104 3.89 0.995    0.699\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt    0.828 0.848 0.866\nDuhachek 0.828 0.848 0.868\n\n Reliability if an item is dropped:\n                   raw_alpha std.alpha G6(smc) average_r   S/N alpha se   var.r\ntrust_t1_item1         0.782     0.800   0.798     0.501  4.01  0.01532 0.06423\ntrust_t1_item2         0.921     0.923   0.904     0.749 11.92  0.00524 0.00336\ntrust_t1_item3_inv     0.791     0.814   0.823     0.522  4.38  0.01512 0.07847\ntrust_t1_item4         0.801     0.818   0.826     0.529  4.49  0.01427 0.07779\ntrust_t1_item5         0.770     0.791   0.784     0.487  3.79  0.01621 0.05985\n                   med.r\ntrust_t1_item1     0.481\ntrust_t1_item2     0.742\ntrust_t1_item3_inv 0.507\ntrust_t1_item4     0.510\ntrust_t1_item5     0.473\n\n Item statistics \n                     n raw.r std.r r.cor r.drop mean   sd\ntrust_t1_item1     600 0.875 0.888 0.886  0.799 4.10 1.15\ntrust_t1_item2     600 0.556 0.518 0.314  0.301 2.71 1.46\ntrust_t1_item3_inv 600 0.854 0.856 0.818  0.748 4.34 1.33\ntrust_t1_item4     600 0.829 0.847 0.804  0.736 3.67 1.09\ntrust_t1_item5     600 0.900 0.909 0.919  0.830 4.64 1.24\n\nNon missing response frequency for each item\n                       1     2     3     4     5     6     7     8     9 miss\ntrust_t1_item1     0.008 0.073 0.217 0.330 0.267 0.097 0.007 0.002 0.000    0\ntrust_t1_item2     0.265 0.228 0.222 0.145 0.102 0.033 0.005 0.000 0.000    0\ntrust_t1_item3_inv 0.013 0.062 0.197 0.265 0.283 0.127 0.048 0.003 0.002    0\ntrust_t1_item4     0.018 0.122 0.293 0.342 0.185 0.038 0.002 0.000 0.000    0\ntrust_t1_item5     0.005 0.032 0.152 0.248 0.323 0.180 0.058 0.000 0.002    0\n```\n\n\n:::\n:::\n\n\n\n\nNote that this way of setting the nr of digits is specific to the `psych` package.\n\n:::\n\nThis gives quite a lot of output. These are the most important parts to consider:\n\n1. **Cronbach's alpha**: At the top we have a row that says `raw_alpha`, `std.alpha`, etc. Here we are just interested in the `raw_alpha`, which is the value of Cronbach's alpha. In this case it's 0.85, which is already very good. \n2. **Reliability if an item is dropped**: This part shows you what would happen to the `raw_alpha` (and the other reliability measures) if you would drop one of the items from the scale. In our data we see that if `item2` would be dropped, the `raw_alpha` would go up to `0.92` (from 0.85). In other words, if we would use a 4-item scale with `item2` dropped, the scale would be more reliable.  \n3. **Item statistics**: This part shows you some usefull statistics about the items, like the mean and standard deviation (sd). More importantly, it also shows several scores for `item-total correlation` (the `r` in `raw.r`, `std.r`, `r.cor` and `r.drop` stands for correlation). This indicate how strongly the item is correlated to the total scale (i.e. the combination of the other items). The recommended correlation measure to look at is the `r.cor` (correlation corrected for item overlap). In our data we see that `item5` has the strongest correlation with the total scale, whereas `item2` has the weakets. Notice how this is in line with the `Reliability if an item is dropped` part: if we would drop `item2`, the scale would become more reliable. (Think about why that makes sense!)\n\n### 6. Remove items if necessary\n\nIf the reliability of your scale is too low, you might want to consider removing some items (if you have enough items to spare).\nAbove we saw that if we would drop `item2`, the reliability of the scale would go up to 0.92.\nYou can verify that this is indeed what happens:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n    select(trust_t1_item1, \n           trust_t1_item3_inv, \n           trust_t1_item4, \n           trust_t1_item5) |> \n    alpha()\n```\n:::\n\n\n\n\nYou can verify that the `raw_alpha` is now 0.92.\nSo now we can choose between either using the 4-item scale with an alpha of 0.92, or keeping the 5-item scale with an alpha of 0.85.\nThis is a judgement call, and depends on the context of your research.\nYou might also consider why an items is not working as well as the others (e.g. is it measuring a different aspect of the construct?, or might there be a problem with the item itself, such as confusing formulation?).\nGenerally speaking, if you're alpha is on the lower end (< 0.7) and you have items to spare (> 3), it's a good idea to remove some items.\n\n### 7. Calculate the scale score\n\nFinally, once you have a reliable scale, you can calculate the scale score.\nThis is usually done by taking the average of the items in the scale.\nThe simplest way to do so is to just add up the items and divide by the number of items.\nLet's do this for the 5-item scale ($\\alpha = 0.85$) that we tested above (mind the parentheses!):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n    mutate(trust_t1_scale = (trust_t1_item1 + trust_t1_item2 + trust_t1_item3_inv + trust_t1_item4 + trust_t1_item5) / 5)\n```\n:::\n\n\n\n\nSo now we have a new column `trust_t1_scale` that contains the scale score.\n\nRemember that in the practice data we already had a column `trust_t1` for the 5-item scale.\nSo this is how that column was created.\nYou can verify this by checking whether the new column is identical to the old one:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(d$trust_t1, d$trust_t1_scale)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}