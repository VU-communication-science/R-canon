{
  "hash": "6d1681ab45ed1a2fe6d052c2c73a71b7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Standardization\nsubtitle: Transforming variables to a common scale\n---\n\n\n\n\n# What is standardization?\n\nStandardization is a technique for transforming data into a consistent scale. It involves two key components: **centering** and **scaling**.\n\n* Centering shifts the data so that its mean becomes zero.\n* Scaling adjusts the data's range by dividing it by the standard deviation.\n\nThe result is that the data is transformed to have a mean of zero and a standard deviation of one. \nWe then also refer to the values of the transformed data as **z-scoreds**.\nStandardizing a variable to z-scores has a number of benefits, and you'll see that we use standardization in different contexts throughout this book:\n\n* **Interpretability**: Standardized variables can be interpreted in the same way. Since zero is the mean, positive values indicate that the observation is above average, and negative values indicate that it is below average. \nA value of 1 means that the observation is one standard deviation above the mean.\n* **Comparability**: Standardization allows you to compare variables that have different units or scales. \nIt allows us to compare *age* and *income*, even if one is measured in years and the other in euros.\n* **Correlation analysis**: If you calculate the covariance of two standardized variables, you get the [correlation coefficient](../concepts/covariance-and-correlation.qmd), which is a useful measure of the strength and direction of the relationship between two variables.\n* **Multiple regression**: Standardization can help you compare the strength of the effects of different independent variables in a [multiple regression model](../tests/linear-regression.qmd).\n\n\n# How to standardize variables\n\nLet's first create a simple numeric variable `x` with some values, and calculate its mean and standard deviation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(4, 9, 6, 3, 9, 10)\n\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.833333\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.926887\n```\n\n\n:::\n:::\n\n\n\n\nTo standardize it, we subtract the mean ($\\bar{x}$) from each value, and then divide by the standard deviation ($S_x$):\n$$ z = \\frac{x - \\bar{x}}{S_x} $$\n\nYou can think of this process as **shifting the center** and **stretching the scale** of the data.\nBy subtracting the mean, we shift the center so that the mean becomes zero.\nBy dividing by the standard deviation, we stretch (or squeeze) the scale so that the standard deviation becomes one.\nTry changing the mean and standard deviation in this widget to see this shifting and stretching in action:\n\n\n\n\n\n```{ojs}\n//| echo: false\nviewof numberLine = Inputs.range(\n  [0, 6.83], \n  {value: 6.83, step: 0.01, label: \"MEAN\"}\n)\nviewof standardDeviation = Inputs.range(\n  [1, 2.93], \n  {value: 2.93, step: 0.01, label: \"SD\"}\n)\n\n {\n  const width = 600;\n  const height = 150;\n  const margin = { left: 50, right: 50, top: 20, bottom: 20 };\n  \n  const meanValue = numberLine;\n  const stddevValue = standardDeviation;\n  \n  // Scale based on mean and standard deviation\n  const scaleX = d3.scaleLinear()\n      .domain([meanValue-10 * stddevValue/5, meanValue+10 * stddevValue/5])\n      .range([margin.left, width - margin.right]);\n\n  const axis = d3.axisBottom(scaleX)\n      .ticks(10);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height);\n\n  // Draw the number line axis\n  svg.append(\"g\")\n      .attr(\"transform\", `translate(0, ${height / 2})`)\n      .call(axis);\n  \n  // Add some data points centered around the mean\n  const dataPoints = [meanValue - stddevValue, meanValue, meanValue + stddevValue];\n  const labels  = [\"-1 SD\", \"Mean\", \"+1 SD\"];\n\n  svg.selectAll(\".dot\")\n      .data(dataPoints)\n    .enter().append(\"circle\")\n      .attr(\"class\", \"dot\")\n      .attr(\"cx\", d => scaleX(d))  // Position based on scaled value\n      .attr(\"cy\", height / 2)      // Place them on the number line\n      .attr(\"r\", 5)\n      .attr(\"fill\", \"red\");\n\n  // Label the points\n  svg.selectAll(\".label\")\n      .data(dataPoints)\n    .enter().append(\"text\")\n      .attr(\"x\", d => scaleX(d))\n      .attr(\"y\", height / 2 - 10)\n      .attr(\"text-anchor\", \"middle\")\n      .text((d,i) => labels[i]);\n\n  return svg.node();\n}\n```\n\n\n\n\nNow let's do this in R.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- (x - mean(x)) / sd(x)\n\nmean(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.253666e-17\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n\n\n\nAs you can see, the mean and standard deviation are now zero[^almostzero]\nand one, respectively.\nBut other than that, the distribution of the data is the same!\nYou can see that they're perfectly correlated:\n\n[^almostzero]: Note that instead of a clean zero, you might see a weird number like `9.253666e-16`. This is because computer's have limited precision, and in this case the best it could to is to get *reaaaaally* close to zero.\nThe number is in **scientific notation**, which is used to express really small or really large numbers. The notation can be read as: $9.253666 \\times 10^{-17}$. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(x, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n\n\n\n## Alternative: use the `scale()` function\n\nThere is also a built-in function in R that standardizes variables for you.\nThis function is called `scale()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscale(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\n[1,] -0.9680365\n[2,]  0.7402632\n[3,] -0.2847166\n[4,] -1.3096965\n[5,]  0.7402632\n[6,]  1.0819232\nattr(,\"scaled:center\")\n[1] 6.833333\nattr(,\"scaled:scale\")\n[1] 2.926887\n```\n\n\n:::\n:::\n\n\n\n\nThis actually gives us a bit more than we need[^asvector].\nTo just get a vector of z-scores, we can wrap the `scale()` function in `as.vector()`.\n\n[^asvector]: The `scale()` function doesn't just return the z-scores, but also the mean and standard deviation. Also, the z-scores are returned as a matrix, which is similar but different from a vector. This can cause issues in some functions. Wrapping it in `as.vector()` ensures that we only get a vector with the z-scores.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.vector(scale(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.9680365  0.7402632 -0.2847166 -1.3096965  0.7402632  1.0819232\n```\n\n\n:::\n:::\n\n\n\n\nWe can use this as follows to standardize a variable in a tibble:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ntibble(x=x) |>\n  mutate(x_z = as.vector(scale(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 2\n      x    x_z\n  <dbl>  <dbl>\n1     4 -0.968\n2     9  0.740\n3     6 -0.285\n4     3 -1.31 \n5     9  0.740\n6    10  1.08 \n```\n\n\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}