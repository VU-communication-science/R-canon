{
  "hash": "7ed43f34e0ffef42f0ae544853434c4f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: ANOVA\nsummary: Analysis of variance\n---\n\n\n\n\n\n\n# What is an ANOVA?\n\nANOVA stands for **Analysis of Variance**, which can refer to a number of different statistical tests that are used to compare means between two or more groups.[^ttest]\nIt is a commonly used test in experimental research, where the key independent variable is usually categorical (e.g., treatment groups, control group).\nThere are different types of ANOVA to cover a wide range of research designs.\nThe most common ones are:\n\n* **One-way ANOVA**. \n  * **Purpose**. Compare means *between-subjects* in different groups.[^independent_samples] \n  * **Example**. We want to know how the design of a health care robot affects how *comfortable* people feel about interacting with the robot. To test this we divide participants into three groups, that are shown three different designs ([Alice, Nao](https://vu.nl/nl/onderzoek/meer-over/sociale-robots-voor-de-samenleving-mediapsychologie), and RoboCop). They then answer multiple questions based on which we measure a *comfort rating* [scale](../techniques/scale-construction.qmd). We can now use One-way ANOVA to compare the mean comfort rating between the three groups.\n* **Two-way ANOVA**. \n  * **Purpose**. Compare means *between-subjects* in different groups, for two independent variables. \n  * **Example**. In addition to comparing three different designs, we could also compare between using a *male* or *female* voice. We can then divide participants over six groups (3 designs * 2 voices), and use two-way ANOVA to test whether the design and voice have an effect on the perceived attractiveness, and whether there is an **interaction** between the two.\n* **Repeated measures ANOVA**. \n  * **Purpose**. Compare means *within-subjects* measured at different timepoints.[^repeated_measures] \n  * **Example**. Instead of the self-reporting comfort rating, we could measure how people react to interacting with a health care robot by measuring their *heart rate*. We could then measure the *heart rate* of participants *before*, *during*, and *after* interacting with the robot. We can then use repeated measures ANOVA to compare the *heart rate* at each stage.\n* **Mixed-design ANOVA**.\n  * **Purpose**. Combine *between-subjects* and *within-subjects* factors. \n  * **Example**. This allows us to measure the effect of the design (one-way anova example) on the change in *heart rate* (repeated measures example). We divide participants into three groups that are shown the three different designs, and measure the *heart rate* of participants *before*, *during*, and *after* interacting with the robot. We can then use mixed-design ANOVA to test the effect of the design on the change in *heart rate*.\n\n\n[^ttest]: If you are familiar with the t-test, you can think of ANOVA as a generalization of the t-test, which can only compare two groups.\n\n[^independent_samples]: This is similar to an independent samples t-test, but can be used for more than two groups.\n\n[^repeated_measures]: This is similar to a paired samples t-test, but can be used for more than two groups. This is primarily used for within-subjects designs, where the same participants are measured multiple times. \n\n\n<!-- # How does it work\n\nUnderneath the hood, ANOVA is a linear model just like [regression analysis](../tests/regression.qmd).\nIf you have not yet read the regression tutorial, you can skip this section, and focus first on how to use ANOVA in practice.\n\nYou can think of ANOVA as a special case of regression where the independent variables are categorical.\nIn the regression tutorial we showed you how you can use categorical independent variables in a regression model using dummy variables.\nYou might recall that it's not straightforward to compare all of the groups, or to test overall whether there is a difference between the groups.\nANOVA is a more specialized tool for this purpose.\n\nTo understand how ANOVA is *different* from *regular regression*, you need to understand two concepts.[^not_different]\n\n[^not_different]: We emphasize *different* and *regular regression*, because technically ANOVA is still just a type of regression. By different we here refer to how ANOVA and regression are most commonly used in our field.\n\n* **Contrast coding**. In regression we usually use **dummy coding** for categorical variables, which compares each group to a single reference group. But we can also use **effect coding** to compare each group to the *grand mean* (the mean of all groups). \n* **Sum of squares**. In a linear model we use sum of squares to assess how much variance is explained by the model. ANOVA allows using different types of sum of squares (Type I, II, III) for different purposes. In most cases researchers use Type III sums of squares (which is the default in popular statistics software like SPSS).\n\n\n\nIn the social sciences, when researchers use ANOVA, they usually use Type III sums of squares and effect coding. In popular statistics software like SPSS, this is also the default approach.\nIn this tutorial we will also stick to this default.\nBut as you'll see in the code, we do need to specify ourselves that we want to use Type II sums of squares and effect coding (specifically we'll use Helmert coding). -->\n\n\n# How to use it\n\nWe'll use the `afex` and `emmeans` packages to perform ANOVA tests, and we'll use the `sjPlot` package to visualize the results.\nTo prepare the data we'll again use the `tidyverse` package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(afex)\nlibrary(emmeans)\nlibrary(sjPlot)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n\nFor our examples we'll use our [Practice data](../../data-management/index.qmd#practice-data).\nIn this data have a (fictional) experiment where we study the effect of popular media on people's trust in journalists.\nSpecifically, we're using the following variables:\n\n* **id**. A unique identifier for each participant.\n* **experiment_group**. The group that participants were assigned to. Each group viewed a different movie that was either *neutral* (control), *positive*, or *negative* about journalism.\n* **np_subscription**. Whether participants have a subscription to a national newspaper, with values *yes* or *no*.\n* **trust_t1** and **trust_t2**. The trust in journalists, measured before (t1) and after (t2) watching a movie about journalism.\n\nThe **experiment_group** and **np_subscription** variables are our independent variable. To use these in the ANOVA, we'll explicitly convert them to factors, to indicate that they are categorical variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- read_csv(\"https://tinyurl.com/R-practice-data\") |>\n        mutate(experiment_group = as.factor(experiment_group),\n               np_subscription = as.factor(np_subscription))\n```\n:::\n\n\n\n\n\n## One-way ANOVA\n\nIn one-way ANOVA we compare the means of a dependent variable between two or more groups in a single independent variable.\nWe can use this to test the main question of our experiment: whether the movie (*experimental_group*) has an effect on the trust in journalists (*trust_t2*).[^trust_t2]\n\n[^trust_t2]: We're using the trust score *after* watching the movie. It is *ok* to ignore the trust score before watching the movie, because we've randomly assigned participants to the different groups. This means that the trust score before watching the movie should be the same in each group. However, as we'll show below, we could also use a repeated measures ANOVA to compare the trust score before and after watching the movie.\n\nWe use the `aov_car` function from the `afex` package to fit the ANOVA model.\nThe formula that we use in this function is, as usual, `dependent_variable ~ independent_variable`.\nHowever, we also need to specify the unique user id (`id`) using the `Error` function.\nThis way we explicitly clarify that each row in the data belongs to a unique participant in the study, which prevents you from mixing up between-subjects and within-subjects effects (more on this in the *repeated measures* section)\nSo the full formula is `dependent_variable ~ independent_variable + Error(id)`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm = aov_car(trust_t2 ~ experiment_group + Error(id), data=d)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: trust_t2\n            Effect     df  MSE         F  ges p.value\n1 experiment_group 2, 597 2.95 34.13 *** .103   <.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\nWhen we print the output of the `aov_car` function, we get the main results of the ANOVA test.\nIn this one-way ANOVA we have a single independent variable, which is the `experiment_group`.\nThe output shows us the results of the F-test ($F_{2, 597} = 34.13, p < 0.001$) which tells us that the difference between the groups is **significant**.\nIn other words, the movie that participants watched had a significant effect on their trust in journalists.\n\nWe also get an $eta^2$ (eta squared) value in the `ges` column (generalized eta squared),\nThis is a measure of **effect size** that tells us how much variance in the dependent variable is explained by the independent variable (similar to the $R^2$ value in regression).\n\n### Comparing between groups\n\nThe $eta^2$ and F-test only tell us that there is a difference between the groups, but not *where* the difference is.\nTo compare bewteen the groups, we can first of all look at their means.\nFor this we'll use the `emmeans` function from the `emmeans` package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans = emmeans(m, \"experiment_group\")\nmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n experiment_group emmean    SE  df lower.CL upper.CL\n control            5.33 0.121 597     5.09     5.57\n negative           4.28 0.121 597     4.04     4.52\n positive           5.63 0.121 597     5.40     5.87\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\n\nNow we can see that the lowest trust score is in the *negative* group, and the highest in the *positive* group.\nHowever, we do not yet know whether the diffences between all the groups are significant.\nIt could be that the *positive* group is significantly higher than the *negative* group, but not significantly higher than the *control* group.\nTo test this we can use the `pairs` function to get the pairwise comparisons for the means we just computed.\nWith `adjust = 'bon'` we use the Bonferroni correction to adjust for multiple comparisons[^multiple_comparisons].\n\n[^multiple_comparisons]: When you compare multiple groups, the chance of finding a significant difference by random chance increases. The Bonferroni correction adjusts the p-values to account for this.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(means, adjust='bon')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast            estimate    SE  df t.ratio p.value\n control - negative     1.047 0.172 597   6.097  <.0001\n control - positive    -0.306 0.172 597  -1.780  0.2265\n negative - positive   -1.352 0.172 597  -7.877  <.0001\n\nP value adjustment: bonferroni method for 3 tests \n```\n\n\n:::\n:::\n\n\n\n\n\nHere we see all possible combinations of groups.\nThe **control - negative** (control *minus* negative) row tells us how much the trust score in the control group is higher than in the negative group, and whether this difference is significant.\n\nFinally, we can visualize the results.\n`afex` has a built-in plot function (afex_plot), but throughout this book we often use the flexible `plot_model` function from the `sjPlot` package, and we can use this here as well!\nWe can get the linear model from the `aov_car` output using `$lm`, and then use the `plot_model` function to visualize the results.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m$lm, type='pred', terms='experiment_group')\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Two-way ANOVA\n\nIn a two-way ANOVA we compare the means of a dependent variable between two or more groups in two independent variables.\nTo demonstrate this we'll use the `np_subscription` variable as a second independent variable.\n\nThe formula for a two-way ANOVA is `dependent_variable ~ independent_variable_1 * independent_variable_2 + Error(id)`.\nThe `*` symbol is a shorthand for including both the main effects and the interaction effect between the two independent variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm = aov_car(trust_t2 ~ experiment_group * np_subscription + Error(id), data=d)\n```\n:::\n\n\n\n\n\nNow our output shows three F-tests: one for the main effect of `experiment_group`, one for the main effect of `np_subscription`, and one for the interaction effect between the two. We also get three $eta^2$ values, one for each effect, which tell us how much variance is explained by each effect.\n\n### Comparing between groups\n\nWe can again use the `emmeans` function to get the means for each group.\nHowever, we have quite a lot of combinations now.\nWe have 6 groups (3 groups * 2 subscription types), which makes 15 pairwise comparisons.\n\nLet's visualize the results first to get a better idea of how the two independent variables interact to affect the trust in journalists.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m$lm, type='pred', terms=c('experiment_group', 'np_subscription'))\n```\n\n::: {.cell-output-display}\n![](anova_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\nHere we see that the effect of `np_subscription` (having a newspaper subscription) mostly matters for the *negative* group.\nIt seems that overall people that watched a *negative* movie have a lower trust in journalists, but this is mostly true for people that do not have a newspaper subscription.\nIn other words, people that have a newspaper subscription might not be as affected by the negative movie.\n\nWe can now use the `emmeans` function to test these differences.\nTo see how the effect of `experimental_group` is different for people that do or do not have a newspaper subscription, we can look at means of the `experiment_group` variable conditional on (`by`) the `np_subscription` variable.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans = emmeans(m, 'experiment_group', by='np_subscription')\nmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnp_subscription = no:\n experiment_group emmean    SE  df lower.CL upper.CL\n control            5.17 0.183 594     4.82     5.53\n negative           3.31 0.173 594     2.97     3.65\n positive           5.63 0.171 594     5.29     5.96\n\nnp_subscription = yes:\n experiment_group emmean    SE  df lower.CL upper.CL\n control            5.43 0.151 594     5.14     5.73\n negative           5.07 0.157 594     4.77     5.38\n positive           5.64 0.158 594     5.33     5.95\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\npairs(means, adjust='bon')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnp_subscription = no:\n contrast            estimate    SE  df t.ratio p.value\n control - negative     1.860 0.252 594   7.393  <.0001\n control - positive    -0.452 0.250 594  -1.804  0.2153\n negative - positive   -2.312 0.244 594  -9.491  <.0001\n\nnp_subscription = yes:\n contrast            estimate    SE  df t.ratio p.value\n control - negative     0.360 0.217 594   1.656  0.2947\n control - positive    -0.208 0.218 594  -0.951  1.0000\n negative - positive   -0.568 0.223 594  -2.550  0.0330\n\nP value adjustment: bonferroni method for 3 tests \n```\n\n\n:::\n:::\n\n\n\n\n\nWe can now compare how the movie affects the trust in journalists, while taking into account how this is conditional on whether people have a newspaper subscription.",
    "supporting": [
      "anova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}