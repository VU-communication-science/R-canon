{
  "hash": "8e35863b3846b2d1d17cbb52839dd393",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Linear regression\nsubtitle: \"Predicting one variable from another\"\nformat:\n  html:\n    df-print: kable\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n# What is regression analysis?\n\nRegression analysis is a statistical technique for *predicting* a `dependent variable` (DV) based on one or more `independent variables` (IVs)\nWe use *predict* in a statistical sense, meaning that we are estimating how well we can guess the dependent variable given knowledge of the independent variable(s).\nThe reason we want to do this is usually not to make actual predictions, but to understand the world better.\nIf we can model how a variable is predicted by one or more other variables, we can make inferences about the relationship between these variables.\nSpecifically, regression analysis allows us to test hypotheses of the sort:\n\n* Older people have more trust in journalists\n* People on the political left have more trust in journalists than people on the political right\n\nIndividually, you could test these hypotheses with a correlation test and a t-test, respectively.\nWith regression analysis, you can test these hypotheses in the same model, while also **controlling** for the relations between the independent variables.\nThis allows us to deal with **confounding**, which can be critical when working with observational data.\nFor instance, if younger people are more likely to be on the political left, then in order to test the effect of political orientation on trust, we need to somehow control for age.\n\nThis is a long tutorial, split up in three parts.\nWe first discuss how regression analysis works under the hood. \nWe won't go deep into the math, but a basic understanding of the regression equation and the $R^2$ value is helpful for understanding when and how to use regression analysis.\nIf you already familiar with regression, and are just here to learn how to do it in R, you can safely skip this part.\nSecond, we'll show you how to use regression analysis in practice, where we go over a number of examples.\nIf you're new to regression, but you're the learning by doing type, you might want to start here.\nFinally, we'll talk about when you can use regression analysis, and what the assumptions are that you need to meet.\nUnderstanding the assumptions is important, but requires a good understanding of the basics. \nSo we advice first getting comfortable with the previous parts before diving in.\n\n# How does it work? \n\nIn **simple linear regression** we have a dependent variable `Y` and an independent variable `X`, and we want to predict `Y` based on `X`.\nThe goal is to find a mathematical formula that best describes their relationship.\nYou can visually think of this as a scatterplot, where we draw a `regression line`  such that the distance between the line and the data points is as small as possible.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n\n\n\nThis visualization corresponds to the **regression equation**.\nWe've coloured the different parts of the equation according to the colours used in the visualization. \n\n\n$$ \\Large  \\color{Green} Y_i = \\color{Blue} b_0 + b_1 X_i + \\color{Red} \\epsilon_i $$\n\n* $\\color{Green} Y_i$ represents the real values of the dependent variable ($Y_1, Y_2, ... Y_n$) that we want to predict.\n* $\\color{Blue} b_0 + b_1 X_i$ represents our prediction of y. It has two coefficients: \n  * **intercept** $\\color{Blue} b_0$: The value of Y when X is zero.\n  * **slope** $\\color{Blue} b_1$: How much Y changes for every unit increase in X.\n* $\\color{Red} \\epsilon_i$ represents the **residual**. This is the distance between the <span style=\"color:blue;\">predicted</span> and the <span style=\"color:green\">real</span> value of Y.[^error]\n\n[^error]: For example, at $X = 10$, the blue line predicting Y passes through the point $Y = 10.45$.\nHowever, the real value of Y at this point is 8.66. \nSo the residual $\\epsilon_i$ at this point is $8.66 - 10.45 = -1.79$.\n\nBased on this equation, we can learn two important things about the relationship between X and Y:\n\n1. **The effect of X on Y**: The slope $b_1$ tells us how much Y changes for every unit increase in X.\n2. **The model fit**: Based on the residual $\\epsilon_i$ we can calculate how well the model fits the data.\n\n### The effect of X on Y\n\nBased on the coefficients of the regression model, we can make inferences about the relationship between the variables.\nIn the example, we see that there is a positive relationship between `X` and `Y`, because the slope is positive.\nIf X goes up, then Y tends to go up as well. \nThis relation is expressed by the coefficient $b_1$, which in our example is 0.95.\nFor every unit increase in X, Y increases by 0.95.\n\nWe can also interpret the intercept ($b_0$), which is the value of Y when X is zero.\nHowever, this is not always meaningful.\nFor example, if the independent variable is `age`, then the intercept would be the predicted value of Y for a person that is 0 years old.\nThis is why the intercept is often not interpreted. \n\n### Model fit\n\nBased on the coefficient of the independent variable we can say something about the relation between X and Y.\nHowever, this is not the full story.\nBased on the coefficients we can make a prediction of Y, but we don't yet know how good this prediction is.\nThis is why we also need the **coefficent of determination** ($R^2$), which tells us how well the model fits the data.\n\nWe can calculate this based on the residual $\\epsilon_i$.\nThe residuals tell us how bad our prediction is for each data point.\nTo get a single score for how bad our prediction is for all data points, we can calculate the **residual sum of squares** ($SS_R$).\nAs the name implies, we take the sum of the squared residuals.\n\n$$  SS_R = \\large \\sum_{i=1}^{n} {\\color{red} \\epsilon_i^2} $$\n\nYou can think of the $SS_R$ as the variance of the real values of Y around the predicted values of Y.\nIf our model is perfect, then the $SS_R$ would be zero. \nBut how do we know how not-perfect our model is? how high is too high?\nFor this, we can look at the **total sum of squares** ($SS_T$), which is the sum of the squared differences between the real values of Y and the mean of Y.\n\n$$ SS_T = \\sum_{i=1}^{n} (Y_i - \\bar{Y})^2 $$\n\nThe $SS_T$ is the **total variance** in Y.\nNotice that the calculation is similar to the $SS_R$, but instead of the predicted values of Y, we use the mean of Y.\nSo now we can use this to see how much better our prediction is than just using the mean of Y.\nBy subtracting the variance that we did not explain ($SS_R$) from the total variance ($SS_T$), we get the variance that we did explain, called the **model sum of squares** ($SS_M$).\n$$ SS_M = SS_T - SS_R $$\n\nAnd now we can calculate the $R^2$ value: the proportion of the total variance that has been explained by our model.\n$$ R^2 = \\frac{SS_M}{SS_T} $$\n\nThe $R^2$ is a value between 0 and 1, that tells us how much of the variance in the dependent variable is explained by the independent variable(s).\nIn our example the $R^2$ is 0.79, which means that 79% of the variance in Y can be explained by the variance in X.\nThis is **very high**, especially for social science data.\nWhen we're trying to predict human behaviour, we're usually already happy if we can explain a few percent of the variance.\n\n::: {.callout-tip title=\"Interactive widget for building intuition\" collapse=\"true\"}\n\nTry for yourself how the regression line changes when you change the values of the intercept and slope!\nThe goal is to get the lowest possible SSE (and the highest possible R2), which means that the line is as close as possible to the data points.\n\nNote that because you're manually tweaking the intercept and slope, you might actually create a model that is worse than the mean of Y, which is why you can get a negative $R^2$.\nIn a regression model this is not possible, because it will always find a model that is at least as good as the mean of Y.\n\n\n\n\n\n```{ojs}\n//| echo: false\nviewof intercept = Inputs.range(\n  [-8, 6], \n  {value: 3, step: 0.001, label: \"b0 Intercept\"}\n)\nviewof slope = Inputs.range(\n  [0.5,1.8], \n  {value: 0.5, step: 0.001, label: \"b1 Slope\"}\n)\n```\n\n```{ojs}\n//| echo: false\nx_line = Array.from({ length: 100 }, (_, i) => i-5);\ny_line = x_line.map(x => slope * x + intercept);\nmutable SSR = 0\nmutable R2 = 0\n\nSST = {\n  let sst = 0\n  let mean = 0\n  y.forEach((d, i) => {\n    mean += y[i] / y.length\n  })\n  y.forEach((d, i) => {\n    sst += Math.pow(y[i] - mean, 2)\n  })\n  return(Number(sst.toFixed(2)))\n}\n\nupdate_SSR = {\n  let ssr = 0\n  x.forEach((d, i) => {\n    ssr += Math.pow(y[i] - (slope * x[i] + intercept), 2)\n  })\n  mutable SSR = Number(ssr.toFixed(2))\n  mutable R2 = Number((1 - SSR / SST).toFixed(2))\n}\n\n// Now, plot the regression line\nPlot.plot({\n  marks: [\n    Plot.lineY(y_line, {x: x_line, stroke: \"blue\"}),\n    Plot.dot(x, {x: x, y: y, fill: \"darkgreen\"}),\n    Plot.text([{intercept,slope}], {x: 10, y: 3, text: d => `prediction = ${d.intercept.toFixed(2)} + ${d.slope.toFixed(2)} * X`, fill: \"black\", fontSize: 16, fill: \"blue\", textAnchor: \"start\"}),\n    Plot.text([{SSR, R2}], {x: 10, y: 0, text: d => `R2 = ${d.R2} = ${(SST - d.SSR).toFixed(2)} / ${SST}`, fill: \"black\", fontSize: 16, fill: \"black\", textAnchor: \"start\"})\n  ],\n  x: {\n    label: \"X\",\n    domain: [-5, 20]\n  },\n  y: {\n    label: \"Y\",\n    domain: [-5,22]\n  },\n  height: 300\n})\n\n```\n\n\n\n\n::: {.callout-tip title=\"Spoiler\" collapse=\"true\"}\n\nThe optimal values for the intercept and slope are $b_0 = 0.930$ and $b_1 = 0.952$.\nThis should give you an $R^2$ of $0.79$.\n\n\n:::\n:::\n\n\n\n# How to use\n\nWe'll show you how to use regression analysis in several steps:\n\n* First, we'll look at **simple linear regression** with a single numeric independent variable.\n* Then, we'll perform a **multiple regression** with two numeric independent variables, and show you how this allows you to **control** for the relations between the independent variables.\n* In the third step we'll show you how to use a **categorical independent variable** in the regression model.\n* Finally, we'll show you how to use **interaction effects** in the regression model, and how you can use this to test **moderation**.\n\nWe'll be using our standard (simulated) practice data, and a bit of `tidyverse` to load and clean the data.\nWe'll also be using the `sjPlot` package, which can create nice tables and plots of regression models.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sjPlot)\n\nd <- read_csv(\"https://tinyurl.com/R-practice-data\") |>\n        mutate(age = if_else(age > 100, 2024 - age, age)) |>\n        select(age, political_orientation, political_interest, trust_t1, \n               news_consumption = `news consumption`)\nd\n```\n:::\n\n\n\n\n\n## Simple linear regression \n\nWe start with the example of predicting `trust` in journalists based on `age`.\nFor this we'll be using the `trust_t1`[^1] variable as the dependent variable, and the `age` variable as the independent variable.\nWe can use the `lm()` function to create a linear regression model.\nInside the `lm()` function we specify the formula for the regression, which has the format `dependent ~ independent`. \n\n[^1]: We use the `trust_t1` variable here, because for the current analysis we are not interested in the effect of the experimental group. Since `trust_t1` is measured before the experiment, it is not influenced by the experiment.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(trust_t1 ~ age, data = d) \n```\n:::\n\n\n\n\nThe *standard* way to inspect the results is using the `summary(m)` function.\nThis gives you all the information you need, but not in a very nice and readable format.\nWe will therefore be using the `tab_model()` function from the `sjPlot` package to get a nice table of the results with some additional statistics (like the confidence intervals for regression coefficients).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(m)\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.80&nbsp;&ndash;&nbsp;4.35</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">age</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00&nbsp;&ndash;&nbsp;0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.210</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">595</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.003 / 0.001</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\n::: {.callout-caution title=\"Backup plan if tab_model doesn't work\" collapse=\"true\"}\n\nThe `tab_model` function by default shows the regression table in your `viewer` pane.\nIf this for some reason doesn't work, you can also use the `use.viewer=F` argument to show the table in your default web browser.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(m, use.viewer=F)\n```\n:::\n\n\n\n\n:::\n\n::: {.callout-note title=\"Confidence intervalls without tab_model\" collapse=\"true\"}\n\nIn case you want to calculate the confidence intervals yourself, instead of using the `tab_model` function, you can use the `confint()` function.\nHere you provide the model as an argument, and you can also specify the level of the confidence interval (default is 95%).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(m)\nconfint(m, level = 0.95)\n```\n:::\n\n\n\n\n:::\n\nThe output of the regression analysis gives us values for two coefficients: the **(intercept)** and the **age** variable (like $b_0$ and $b_1$ in the regression equation).\nWe get the coefficient **estimates** and **p-values** that tell us if these coefficients are statistically significant.\nWith `tab_model` we also get the **confidence interval**. \n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n* The coefficient for the `intercept` tells us the predicted value of `trust_t1` when `age` is zero.\nThis is not very meaningful in this case, because we don't have any people with an age of zero in our data.\n* The coefficient for `age` tells us how much `trust_t1` changes for every *unit increase* in `age`. \n  * Our `age` variable is in years, so the coefficient 0 tells us that for every year of age, trust in journalists increases on average by 0 points.\n  * The p-value of `< 0.001` tells us that this effect is statistically significant.\n  * The confidence interval tells us that we are 95% confident that the true effect of `age` on `trust_t1` is between 0 and 0.01.\n\nWe also get the $R^2$ value, which tells us how well the model fits the data.\nHere we see that the $R^2$ is 0.003, which means that 0.3% of the variance in `trust_t1` can be explained by the variance in `age`.\n\nIn conclusion, this model shows that (in our simulated data) there is a positive effect of `age` on `trust_t1`.\n\n  \n## Multiple regression\n\nIn the previous example we used a single independent variable (`age`) to predict the dependent variable.\nNow we'll add a second numeric independent variable (`news_consumption`) to the model.\nThis is called **multiple regression**, and it allows us to test the effect of multiple variables on the dependent variable at the same time.\nThe formula for using multiple independent variables is: `dependent ~ independent1 + independent2 + ...`.\n\nAs we mentioned earlier, by including both variables in the model we can test the effect of `news_consumption` on `trust` while *controlling* for `age`, and vice versa.\nTo better investigate the effects of controlling, it is good practise to show multiple versions of the model side by side, which we can do by passing multiple models to the `tab_model()` function.\nTo better compare effect sizes, we also include the **standardized coefficients**, which we can do with `show.std = T` in the `tab_model()` function.\nTo keep the table simple, we won't show the confidence intervalls this time (`show.ci = F`).\n\n::: {.callout-tip title=\"Standardized coefficients\" collapse=\"true\"}\n\nThe **standardized coefficients** are the coefficients of the model if all variables are standardized.\nThis means that the variables are transformed to have a mean of 0 and a standard deviation of 1.\nThis makes the coefficients comparable, because they are now in terms of standard deviations.\n\nThink for a second why this makes sense. \nIf you have a variable that goes from 0 to 100, and another variable that goes from 0 to 1, then the coefficients of these variables will be on completely different scales.\nRecall that the coefficient tells us how much the dependent variable changes for every **unit increase** in the independent variable.\nA **unit increase** of 1 on a scale from 0 to 100 is very different from a **unit increase** of 1 on a scale from 0 to 1.\nAnd even if two variables are both on a scale from 0 to 1, the effect of a unit increase can still be different if the variables have a different standard deviation.\nBy standardizing the variables, a **unit increase** is now an increase of one **standard deviation**, which is the same for all variables.\n\nYou can request the standardized coefficients with the `show.std = T` argument in the `tab_model()` function.\nThis will report the standardized coefficients (`std. Beta`) next to the regular coefficients (`Estimates`).\n\nAlternatively, you can also use the `rockchalk` package to standardize the entire model.\nThis will give you a new model with standardized coefficients, which you can then use to interpret the effect sizes.\nUsing `show.std = T` in the `tab_model()` function actually does the same thing behind the scenes, so in practice this is often easier.\nBut when first learning about regression analysis, it can be helpful to perform this step yourself to better understand what's going on.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rockchalk)\nm_std <- standardize(m)\ntab_model(m_std)\n```\n:::\n\n\n\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm(trust_t1 ~ news_consumption, data = d)\nm2 <- lm(trust_t1 ~ news_consumption + age, data = d)\ntab_model(m1, m2, show.std = T, show.ci=F)\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Beta</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Beta</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.73</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">news consumption</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.002</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">age</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.688</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">600</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">595</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.018 / 0.017</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.018 / 0.015</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\nIf we look at the first model, we see a significant effect of `news_consumption` on `trust_t1` ($b = 0.04$, $p < 0.05$). \nThe $R^2$ value of 0.018 suggests that `news_consumption` explains 1.8% of the variance in `trust_t1`.\n\nHowever, when we include the `age` variable in the model, we see that the effect of `news_consumption` becomes much weaker ($b = 0.04$, $p = 0.002$).\nAlso, notice that the explained variance ($R^2 = 0.018$) isn't much higher than in the model with just the `age` variable that we saw earlier.\nThis suggests that the effect of `news_consumption` on `trust_t1` is partially explained by `age`.\n\n\nWhat we're witnessing here is a form of **confounding**.\nThere is a relation between the `news_consumption` and `trust_t1` variables, but a part of this relation is **spurious**.\n`age` has an effect on both `news_consumption` and `trust_t1`: older people consume more news, and have more trust in journalists.\nBy controlling for `age`, we can see the real effect of `news_consumption` on `trust_t1` (though we can never be sure that we've controlled for all possible confounders).\nFor a more detailed explanation of confounding, see the [confounding tutorial](../techniques/controlling.qmd).\n\n#### Standardized coefficients\n\nIn the second model we now have two significant effects: `age` and `news_consumption`.\nSo how can we tell which effect is stronger?\nIf we look at the regular coefficients, we see that `age` (0) is quite similar to `news_consumption` (0.04).\nHowever, this is not a good way to compare the effects, because the variables are on different scales.\nA 1 unit increase in `age` is not the same as a 1 unit increase in `news_consumption`.\nBy standardizing the variables, we can compare the effects in terms of standard deviations instead.\nFor every standard deviation increase in `age`, `trust_t1` increases by -0.02 standard deviations.\nFor every standard deviation increase in `news_consumption`, `trust_t1` increases by 0.14 standard deviations.\nSo this suggests that the effect of `age` is stronger.[^test_difference]\n\n[^test_difference]: Note that we have not tested if the difference between the two coefficients is significant. We will not go into this here, but note that the confidence intervalls of the standardized coefficients can provide more confidence in this comparison.\n\n#### Adjusted $R^2$\n\nThis is also a good time to talk about the **$R^2$ adjusted** value.\nThis is the $R^2$ value, but corrected for the number of independent variables in the model.\nThis is important, because the $R^2$ value will always increase when you add more independent variables (i.e. more information) to the model.\nThe $R^2$ adjusted value corrects for this, which is why it's slightly lower.\nSo when you're adding more independent variables to the model, you can use the $R^2$ adjusted value to see if you're not just adding noise.\n\n## Categorical IVs\n\nThe **independent variable** in a regression model can also be categorical.\nThis allows us to include categorical variables in the model, similar to the t-test and ANOVA.\nLet's see what this looks like when we predict `trust_t1` based on the `political_orientation` variable, which has the values `left`, `right` and `center`.\n\nWe cannot directly use the values \"left\", \"right\" and \"center\" in the regression equation, but we create so-called **dummy variables**.\nA dummy variable is a *binary* variable (i.e., it can only take the values `0` and `1`) that represents whether something is the case or not.\nSo if we want to test whether people that lean to the left have more trust in journalists, we can create a dummy variable that is `1` for people with orientation `left`, and `0` for all other people (i.e., `right` and `center`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd = mutate(d, political_left = if_else(political_orientation == \"left\", 1, 0))\n\nselect(d, political_orientation, political_left) ## check the result\n```\n:::\n\n\n\n\nNow we can use this variable in the regression model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(trust_t1 ~ political_left, data = d)\n\ntab_model(m)\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.93&nbsp;&ndash;&nbsp;4.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">political left</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.48&nbsp;&ndash;&nbsp;0.82</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">600</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.088 / 0.087</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nThe interpretation of the results is almost identical to the previous example with the `age` variable.\nThe only thing we need to keep in mind is that the `political_left` variable is binary, so it can only take the values `0` and `1`.\nAccordingly, we don't say that the trust in journalists increases by 0.65 points for every unit increase in `political_left`.\nInstead, we just say that people on the political left (`political_left = 1`) have on average a trust score that is 0.65 points higher than people that are not on the political left (`political_left = 0`).\n\n<!-- Note that in this case we can actually interpret the **intercept**.\nThe intercept is the predicted value of the dependent variable when the independent variable is zero.\nSo in this case, the intercept (`3.83`) is the predicted trust in journalists for people that are NOT `political_left`. -->\n\n### Categories with more than two levels\n\nIn the previous example we created the dummy variable ourselves, but we can also let R do this for us.\nThis is especially convenient if we have more than two categories.\nIn addition, this also has the benefit that `lm` *knows* that the variable is categorical, which enables us (among other things) to visualize the model propertly.\n\nWe first need to make sure that our variable is of the `factor` type[^3].\nThe difference between a `character` and a `factor` is that in a `factor` we explicitly tell R what the categories are, and what the *order* of the categories is.\nThe order is important, because the first category will be the **reference category** (more on this later) in the regression model.\nTo transform our `political_orientation` variable to a `factor` we can use the `factor()` function, and provide the `levels` argument to specify the order of the categories.\n\n[^3]: You *can* also use a `character` variable directly, but the `factor` type is more appropriate for categorical variables. It also let's you specify the order of the categories, which is important for regression analysis because it let's you specify the reference category.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mutate(d, political_orientation = factor(political_orientation, levels=c('center','left','right')))\n```\n:::\n\n\n\n\nNow, when we use the `political_orientation` variable in the regression model, R will automatically create the dummy variables for us.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(trust_t1 ~ political_orientation, data = d)\ntab_model(m)\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.15&nbsp;&ndash;&nbsp;4.43</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">political orientation<br>[left]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.20&nbsp;&ndash;&nbsp;0.59</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">political orientation<br>[right]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.49</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.68&nbsp;&ndash;&nbsp;-0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">600</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.125 / 0.122</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\nNotice that there are now two coefficients for the `political_orientation` variable: one for `left` and one for `right`.\nWhy 2, and not 3?\nThis is because we only need two dummy variables to represent three categories.\nYou can see how this works in the following table:\n\n| political_orientation | is_left | is_right |\n|-----------------------|---------|----------|\n| left                  | 1       | 0        |\n| right                 | 0       | 1        |\n| center                | 0       | 0        |\n\nThe `center` category is now the **reference category**.\nRecall that the intercept is the predicted value of the dependent variable when the independent variables are zero.\nIn this model, the intercept therefore represents the predicted value of `trust_t1` for people in the `center` category.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\nThe effects of the `left` and `right` categories only tell us how much the trust in journalists changes for people in these categories **compared to people in the reference category**.\nSo the `political_orientation [left]` coefficient tells us that `trust` is for people in the `left` category is 0.39 points higher than for people in the `center` category.\nThe `political_orientation [right]` coefficient tells us that `trust` is for people in the `right` category is -0.49 points lower than for people in the `center` category.\nBased on this model, we cannot directly compare the `left` and `right` categories, because the `center` category is the reference category.\n\n::: {.callout-note title=\"Determining what reference category to use\" collapse=\"true\"}\n\nDepending on your hypotheses, you might want to use a specific category as the reference category.\nYou can do this by changing the order of the levels in the `factor()` function.\nThe first level will always be the reference category.\nSo in the following example, the `left` category is the reference category.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2 <- mutate(d, political_orientation = factor(political_orientation, levels=c('left','center','right')))\n\nlm(trust_t1 ~ political_orientation, data = d2) |>\n    tab_model()\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.68</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.55&nbsp;&ndash;&nbsp;4.82</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">political orientation<br>[center]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.59&nbsp;&ndash;&nbsp;-0.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">political orientation<br>[right]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.89</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.07&nbsp;&ndash;&nbsp;-0.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">600</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.125 / 0.122</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::\n\n## Interaction effects\n\nOne of the strengths of regression analysis is that it allows you to test **interaction effects**.\nThis is when the effect of one independent variable depends on the value of another independent variable.\n\nFor example, in the previous model we saw that `political_orientation` has an effect on `trust_t1`.\nBut we might theorize that this effect depends on a person's overall `political_interest`.\nIf people are not really interested in politics, then their political orientation might not have a big effect on their trust in journalists.\nIn other words, we expect that `political_interest` **moderates** the effect of `political_orientation` on `trust_t1`.\n\nTo test this, we can include an **interaction term** in the regression model.\nThat is, we add an extra term to the formula in which we **multiply** the two independent variables.\nHere we fit two models: one without the interaction term, and one with the interaction term.\nTo keep the table readable, we'll first rename the variables to shorter names.\n\n\n\n\n::: {.cell tab.width='100%'}\n\n```{.r .cell-code}\nds <- rename(d, pol_ori = political_orientation, \n                pol_int = political_interest) \n\nm1 <- lm(trust_t1 ~ pol_ori + pol_int, data = ds)\nm2 <- lm(trust_t1 ~ pol_ori + pol_int + pol_ori*pol_int, data = ds)\n\ntab_model(m1, m2, show.std=T, show.ci=F)\n```\n\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">trust_t1</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Beta</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Beta</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8\">std. p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.92</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.94</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\">0.550</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol ori [left]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.38</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.58</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.128</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol ori [right]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.49</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.47</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.48</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.484</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol int</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.012</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.187</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\">0.187</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol ori [left] × pol int</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.009</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\"><strong>0.009</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pol ori [right] × pol int</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>0.033</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\"><strong>0.033</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">600</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">600</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.134 / 0.130</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.169 / 0.162</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nIn the first model we see roughly the same effects as before for `political_orientation`.\nWe also see that `political_interest` has a significant effect on `trust_t1` ($b = 0.1$, $p < 0.05$).\n\nIn the second model we added the interaction terms.\nOne important thing to note is that this changes the interpretation of the main effects.\nWhen you add an interaction term, the main effects of the variables are now the effect of the variable **when the other variable is zero**.\nThis doesn't always make sense.\nFor instance, the effect of `pol ori [left]` now tells us the effect of `political_orientation` when `political_interest` is zero, but this is impossible because `political_interest` is measured on a scale from 1 to 7.\nOften, we therefore don't report the main effects when we have an interaction term.\nWe'll also skip this for now (but see the optional block if you're interested)\n\n::: {.callout-note title=\"Interpreting main effects with interaction terms\" collapse=\"true\"}\n\nWhen you add an interaction term, the main effects of the variables used in this term are now the effect of the variable **when the other variable is zero**.\nAs we mentioned, sometimes this doesn't make sense.\nHowever, we can **make it make sense**, if we rescale the variables so that the value zero is meaningful.\nWe could for instance **center** the variables.\nThis way, zero is the mean of the variable, and the main effects are the effect of the variable at the mean of the other variable.\n\nThis is also why in the model we see very different results for the **unstandardized** and **standardized** coefficients.\nStandardized coefficients are centered, so they are the effect of the variable at the mean of the other variable.\nThis is also why we now get an additional `std. p` column, which gives us the p-value of the standardized coefficients.\nIn our model, the unstandardized coefficients are not significant, but the standardized coefficients are.\nLet's separately interpret the unstandardized and standardized coefficients for the `political_orientation` effects.\n\n* Unstandardized coefficients:\n  * `pol_ori [left]`: The effect of `political_orientation` on `trust_t1` when `political_interest` is zero is not significant.\n  * `pol_ori [right]`: The effect of `political_orientation` on `trust_t1` when `political_interest` is zero is not significant.\n\nThese effects should not be interpreted, because `political_interest` is a scale from 1 to 7, so a value of zero is not meaningful.\nIt just *happens* to be the case that as you extrapolate to a `political_interest` of zero (i.e. go to the left on the plot below) there is no expected difference in `trust_t1` between people with different `political_orientation`.\n\n* Standardized coefficients:\n  * `pol_ori [left]`: The effect of `political_orientation` on `trust_t1` at the mean of `political_interest` is significant.\n  * `pol_ori [right]`: The effect of `political_orientation` on `trust_t1` at the mean of `political_interest` is not significant.\n\nThese coefficients do have a meaningful interpretation. Based on our analysis we can see that for people with low `political_interest`, there is no significant effect of `political_orientation` on `trust_t1`. \nIf you look at the plot below, you see that the lines overlap at the left. \nAs `political_interest` increases (towards the right), the lines start diverging, indicating that the effect becomes significant at some point. \nThe main effect simply tells us that for the average value of `political_interest`, the effect is already significant.\n:::\n\n\nOur main interest is in the interaction terms.\nThe `pol ori [left] x pol int` coefficient tells us how much the **effect** of `political_orientation` on `trust_t1` changes for every unit increase in `political_interest`.\nThis is positive, which means that the effect of `political_orientation` on `trust_t1` becomes stronger as `political_interest` increases.\nWe see the opposite effect for the `pol ori [right] x pol int` coefficient, which is negative.\n\nThis is notoriously difficult to interpret, so a good technique for interpreting interaction effects is to **plot** the interaction.\nThe `sjPlot` package has the `plot_model()` function, which can plot the predicted values (`type = \"pred\"`) for a selection of terms (`terms = c('pol_int','pol_ori')`).\nThis will show you how the effect of `political_orientation` on `trust_t1` changes as `political_interest` increases.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m2, type='pred', terms = c('pol_int','pol_ori'), \n           show.data = T, jitter = T)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n\nOn the left side of the plot, where political interest is low, we see that there is not yet a significant effect of political orientation on trust in journalists.\nThis makes sense: if you're not interested in politics, then your political orientation might not matter that much.\nHowever, as political interest increases, we see that the line diverge, indicating an increasingly large effect of political orientation.\nWe can thus conclude that **the effect of political orientation on trust in journalists is *moderated* by (i.e. depends on) political interest**.\n\n# Conditions and assumptions\n\nRegression analysis is a very versatile tool that can be used in many different situations.\nHowever, there are some assumptions that need to be met in order to use it correctly.\nThe most important assumptions are:\n\n1. **Linearity**: The relationship between the independent and dependent variable(s) should be linear.\n2. **Normality**: The residuals should be normally distributed.\n3. **No outliers**: Extreme values can have a large effect on the model.\n3. **Homoscedasticity**: The variance of the residuals should be constant.\n4. **Independence**: The observations should be independent of each other.\n5. **No multicollinearity**: In **multiple regression**, the independent variables should not be too highly correlated with each other.\n\nWhether these assumptions are met is generally a grey area.\nIt's not a matter of \"yes\" or \"no\", but rather a matter of \"to what extent\".\nLet's discuss some strategies for checking these assumptions.\n\n### Linearity\n\nRemember that we are trying to fit a straight line through the data.\nIf the relationship between the independent and dependent variable is not linear, then the model will not fit the data well.\nTo check this assumption, you can plot the data and see if a straight line is a good fit.\nWith the `plot_model()` function from the `sjPlot` package you can plot the predicted (`type = \"pred\"`) values for an independent variable (`terms = \"age\"`) on top of the data points (`show.data = T, jitter = T`[^jitter]).\n\n[^jitter]: Jitter is a small amount of noise that is added to the data points to prevent them from overlapping in case their values are the same.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(trust_t1 ~ age, data = d)\n\nplot_model(m, type = \"pred\", terms = \"age\", \n              show.data = T, jitter = T)\n```\n:::\n\n\n\n\nIf you check this plot for our practice data, you'll see that the relationship between `age` and `trust_t1` is indeed linear.\nLet's instead look at an example where the relationship is not linear.\nIn the following plot the relation between `age` and `happiness` is quadratic, following a u-shape.\nYounger and older people tend to be happier than middle-aged people.\nA regular linear model (left) will not be able to capture this relationship well, and will therefore not fit the data well.\nOn the right we fit a regression line to the actual relation. \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n### Normality\n\nThe residuals of the model should be normally distributed.\nIf you look at the figure of the regression model at the top of this tutorial, you can see how the residuals (the red lines) are distributed around the regression line.\nThis distribution should be normal.\n\nYou can to some extend see whether this is the case using the same plot as above. \nBut there are also special diagnostics plots that can help you with this.\nWith the `plot_model()` function you can plot the residuals (`type = \"diag\"`) of the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiag_plots <- plot_model(m, type = \"diag\")\n```\n:::\n\n\n\n\nThis creates a series of plots that show the residuals in different ways.\nWhat diagnostics plots are produced depends on the type of model you have.\nFor regression we get three plots:\n\n* `diag_plots[[1]]`: Non-normality of residuals and outliers\n* `diag_plots[[2]]`: Non-normality of outliers\n* `diag_plots[[3]]:` Homoscedasticity\n\nLet's first focus on the second plot, which shows just the distribution of the residuals.\nThe coloured area is a smoothed density plot of the residuals, and the blue line shows a proper bell curve for reference.\nIf there is a clear difference between the two, then the residuals are not normally distributed.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiag_plots = plot_model(m, type=\"diag\")\ndiag_plots[[2]]\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### No outliers in the residuals\n\nOutliers can have a large effect on the model.\nUsually outliers in the residuals are related to outliers in the variables, which can be detected when [inspecting and cleaning](../techniques/data-cleaning.qmd) the data.\nFor detecting outliers in the residuals, the **Non-normality of residuals and outliers** plot can be helpful.\nIf there are outliers, they will show up as points that are far away from the line.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiag_plots[[1]]\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Homoscedasticity\n\nThe residuals should have a constant variance.\nWhat we mean by this is that among the fitted values in the model, the variance of the residuals should not systematically increase or decrease.\nFor instance, if in our model of **age** predicting **trust** the residuals are very small for young people, and very large for old people, then the model is not homoscedastic.\n\nThis can be checked with the **Homoscedasticity** plot.\nIf the residuals are homoscedastic, then the residuals should be randomly distributed around the horizontal line.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiag_plots[[3]]\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n\n\nNow let's look at an example where the variance of the residuals systematically increases with the fitted values.\nSo the higher our prediction of `trust_t1`, the larger the residuals.\nWe then say that the residuals are **heteroscedastic**.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Independence\n\nIndependence means that the residuals should not be related to each other.\nThere are many ways in which this assumption can be violated.\n\nOne common case is data over time.\nIf you're measuring something over time, like a person's number of social media followers, then it is very common that every observations is highly dependent on the previous observation.\nThis is called **autocorrelation** (the variable correlates with itself).\nIn order to use these data in a regression model, you need to use special techniques that take this autocorrelation into account. \nThis area of statistics is called **time series analysis**.\n\nAnother common case is that your observations are nested within groups.\nFor example, say your measuring the relation between social media use and happiness, and you gathered data from multiple countries.\nObservations nested in countries are not independent, because people within the same country tend to be more similar to each other than people from different countries.\nSome countries are overall happier, and some countries have more social media use.\nCountry therefore could act as a **confounder**.\nTo reduce the dependency between the residuals, you could control for countries using dummy variables, or use more advanced techniques like **multilevel models**.\n\n### No multicolinearity\n\nMulticolinearity is a situation where two or more independent variables are highly correlated with each other.\nThis can cause problems in the model, because the model cannot distinguish between the effects of the two variables.\nTo check for multicolinearity, you can look at the **correlation matrix** of the independent variables (see the [correlation tutorial](../tests/correlation.qmd)).\nA rough rule of thumb is that if the correlation between two variables is higher than 0.5 you should be cautious, and if it's higher than 0.8 you should be very worried.\n\nYou should try to avoid high correlations between independent variables where possible. \nIf you have multiple variables that are highly correlated, they might be measuring a common factor, so you could consider combining them into a single variable (see the [scale construction](../techniques/scale-construction.qmd) tutorial).\n\n::: {.callout-note title=\"The variance inflation factor\" collapse=\"true\"}\n\nA more appropriate way to check for multicolinearity is to use the **variance inflation factor** (VIF).\nLooking just at correlations is actually not good enough.\nThe more accurate definition of multicolinearity is that one independent variable can be predicted by the other independent variables in the model.\nSo looking at bi-variate correlations is not enough, because the prediction of one variable can be spread out over multiple other variables.\n\nIn R we can calculate the VIF of the variables in a model with the `vif()` function from the `car` package.\nThis returns the VIF score for each independent variable.\nIf the VIF is 1 or lower, we don't have to worry about multicolinearity.\nIf it's higher than 5, we very likely have a problem.\nIf it's between 1 and 5, it's a grey area, and you (as always) have to use your judgement.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: carData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'car'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n\n\n:::\n\n```{.r .cell-code}\nm <- lm(trust_t1 ~ age + news_consumption, data = d)\nvif(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             age news_consumption \n        1.322073         1.322073 \n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n# How to report \n\n\nFor APA style reporting of regression analysis, we generally report two things:\n\n* The **coefficients** that we're interested in\n* The **model fit**\n\n## Reporting the coefficients\n\n\n\n1. The **coefficients** of the model, which tell us the effect of the independent variables on the dependent variable. \n2. The **model fit**, which tells us how well the model fits the data.\n\n\n",
    "supporting": [
      "linear-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script type=\"ojs-define\">\n{\"contents\":[{\"name\":\"x\",\"value\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]},{\"name\":\"y\",\"value\":[-0.6814,1.3095,7.6761,4.2115,5.3879,11.1452,8.3827,4.2048,6.9394,8.663,14.6722,13.0794,14.2023,14.332,13.3325,21.3607,18.4936,12.1001,21.1041,18.5816]}]}\n</script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}