{
  "hash": "57f947c74c7ffa15e1348901a5bf4325",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Covariance and correlation\nsubtitle: measuring the relationship between variables\norder: 2\nformat:\n    html:\n        df-print: paged\n---\n\n\n\n\n\n# What are covariance and correlation? \n\nThe **covariance** of two variables tells us something about the extent to which they **change together**.\nIf one variable goes up, does the other variable go up as well?\nThis information is the foundation for many statistical methods, because it enables us to quantify relationships between phenomena.\nFor example, it allows us to measure: *to what extent is a person's social media use related to their feelings of loneliness?*\n\n\nThe **correlation** is a standardized version of the covariance, which expresses the **strength** and **direction** of the relationship between two variables on a scale from -1 to 1.\nThis makes it easier to interpret. Consider the following example:\n\n* if the correlation between a person's social media use and their feelings of loneliness is positive (`> 0`), it means that people that spend more time on social media tend to feel more lonely.\n* If the correlation is negative (`< 0`), it means that people that spend more time on social media tend to feel *less* lonely.\n* If the correlation is (close to) `-1` or `1`, it means that the relationship is strong.\n* If the correlation is (close to) `0`, it means that the relationship is weak or absent.\n\nDeveloping a good intuition for covariance and correlation is important, because it helps you to understand relationships between variables, and to interpret the results of statistical tests.\nIn this tutorial we'll develop this intuition by looking at visualizations, and calculating the covariance and correlation ourselves.\n\n\n# Visualizing covariance and correlation\n\nTo get a good intuition of what covariance and correlation are, it helps to have a visual image.\nOne way to visualize the relation between two variables is to make a scatter plot where one variable is on the x-axis, and the other on the y-axis.\nThis way you can see how the variables **move together**.\n\n* If the correlation is positive, the points will tend to form a line that goes up, because when x goes up, y goes up as well.\n* If the correlation is negative, the points will tend to form a line that goes down, because when x goes up, y goes down.\n* If the relation is strong, the points will clearly form a line.\n* If the relation is weak, the points will be more scattered.\n\nLet's first plot three scenarios, for a **strong positive**, **strong negative**, and **weak correlation**.\nWe'll pretend this is data about **social media use** in hours per day and **feelings of loneliness**.\nAt the top we report the correlation coefficient as **r** and the covariance as **cov**.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](covariance-and-correlation_files/figure-html/unnamed-chunk-1-1.png){width=100%}\n:::\n:::\n\n\n\n\n\n\n\n**Strong positive correlation** ($r = 0.887$).\nOn the left we see a clear, positive relation between social media use and feelings of loneliness.\nWhen social media use goes up, feelings of loneliness go up as well.\n\n**Strong negative correlation** ($r = -0.907$).\nHere the relation is negative (when social media use goes up, feelings of loneliness go down), but it's still a **strong** relation.\nThey still **move together**, only in the opposite direction.\n\n**Weak correlation** ($r = -0.188$).\nHere we see that there is a weak, negative relation.\nWhen social media use goes up, there is a very minor decrease in feelings of loneliness.\n\n\n## The difference between covariance and correlation\n\nIf we look at the plots above, we see that the covariance and correlation are closely related.\nThe difference is that the correlation is **standardized**, while the covariance is not.\nThis means that:\n\n1. The covariance can be any number, while the correlation is always between -1 and 1.\n2. The covariance depends on the *scale* of the variables. \n\nBy the **scale** we mean the units in which the variables are measured.\nFor instance, we can measure social media use in hours or in minutes per day.\nThis shouldn't change the relation between social media use and feelings of loneliness, but it does change the covariance.\n\nTo illustrate this, let's plot the positive correlation scenario from above three times: \n\n* once with the X variable (social media use) in hours \n* once with the X variable in minutes \n* once with both the X and Y variables standardized (i.e, turn them into z-scores).\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](covariance-and-correlation_files/figure-html/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n\n\n\n\nAs we can see, the direction and strength of the relation is the same in all three plots.\nThe only thing that changed is the scale of the variables, which you can see in the X and Y axis.\nThis doesn't affect the correlation ($r = 0.887$ in all three cases), but it does affect the covariance:\n\n* For the original data, the covariance is $1.287$, as we saw before\n* For the data where we increased the scale of X by a factor 60 (to go from hours to minutes), the covariance increased to $76.683$.\n* In the final plot we standardized both the X and Y variables. As a result, the covariance is now identical to the correlation ($r = 0.887, cov = 0.887$). This is what we mean when we say that the correlation is the standardized version of the covariance!\n\n\n# Calculating covariance and correlation\n\nTo round up our understanding of covariance and correlation, let's calculate them ourselves.\nFor this we'll use a toy dataset with two variables, `x` and `y`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nd <- tibble(x = c(20, 10, 30, 40, 50),\n           y = c( 3,  2,  5,  4,  6))\n\nd\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"20\",\"2\":\"3\"},{\"1\":\"10\",\"2\":\"2\"},{\"1\":\"30\",\"2\":\"5\"},{\"1\":\"40\",\"2\":\"4\"},{\"1\":\"50\",\"2\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n## Calculate covariance\n\nThe formula for the calculating the covariance between two variables $X$ and $Y$ in a sample[^1] is:\n\n$$ cov(X, Y) = \\frac{\\sum (X_i - \\bar{X}) (Y_i - \\bar{Y})}{n-1} $$\n\n* $X_i$ and $Y_i$ are the individual values of $X$ and $Y$\n* $\\bar{X}$ and $\\bar{Y}$ are the means of $X$ and $Y$\n* $n$ is the number of observations\n* $\\sum$ is the sum over all observations\n\n[^1]: The formula is different depending on whether you are working with a sample or the entire population. Above we showed the formula for a sample, which is the most common case in practice. To calculate the covariance for the entire population, the only difference is that you would divide by $n$ instead of $n-1$: $\\frac{\\sum (X_i - \\bar{X}) (Y_i - \\bar{Y})}{n}$.\n\nLet's perform this calculation in steps, to make it easier to follow.\nFirst, calculate the means for x and y.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mutate(d, x_mean = mean(x),\n               y_mean = mean(y))\n```\n:::\n\n\n\n\n\nNow calculate the **deviation from the mean** for both variables. \nThis is the $X_i - \\bar{X}$ and $Y_i - \\bar{Y}$ part of the formula.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mutate(d, x_deviation = x - x_mean,\n               y_deviation = y - y_mean)\n```\n:::\n\n\n\n\n\nThen multiply these deviations.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mutate(d, deviation_product = x_deviation * y_deviation)\n```\n:::\n\n\n\n\n\nHave a look at the intermediate results to see what we've done so far.\nTry to do the calculations in your head to see if you understand what's going on.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"x_mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y_mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"x_deviation\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y_deviation\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"deviation_product\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"20\",\"2\":\"3\",\"3\":\"30\",\"4\":\"4\",\"5\":\"-10\",\"6\":\"-1\",\"7\":\"10\"},{\"1\":\"10\",\"2\":\"2\",\"3\":\"30\",\"4\":\"4\",\"5\":\"-20\",\"6\":\"-2\",\"7\":\"40\"},{\"1\":\"30\",\"2\":\"5\",\"3\":\"30\",\"4\":\"4\",\"5\":\"0\",\"6\":\"1\",\"7\":\"0\"},{\"1\":\"40\",\"2\":\"4\",\"3\":\"30\",\"4\":\"4\",\"5\":\"10\",\"6\":\"0\",\"7\":\"0\"},{\"1\":\"50\",\"2\":\"6\",\"3\":\"30\",\"4\":\"4\",\"5\":\"20\",\"6\":\"2\",\"7\":\"40\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\nFinally, sum the deviation products and divide by $n-1$ to get the covariance.\nHere we use the `sum()` function to calculate the sum of the `deviation_product` column, and the `nrow()` function to get the number of observations in the data `d`. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndev_sum = sum(d$deviation_product)\nn = nrow(d)        \ndev_sum / (n - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22.5\n```\n\n\n:::\n:::\n\n\n\n\n\nHere we use the summarize function, which allows us to calculate summarizing statistics functions, such as `sum()` and `n()` (which gives the number of observations).\n\nYou can check your answer by using the `cov()` function, which is R's built-in function for calculating the covariance.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncov(d$x, d$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22.5\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Calculate correlation\n\nThe correlation is the standardized covariance.\nThere are two ways to go about this:\n\n### First standardize the variables, then calculate the covariance\n\nWe can repeat the covariance calculation, but this time standardize the variables first.\nThis is also what we showed in the previous section, where we plotted the data with the variables standardized.\n\nTo standardize a variable, we subtract the mean and divide by the standard deviation (there is also the built in function `scale()` that can do this for you).\nBe carefull to use the parentheses correctly!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- mutate(d, x_z = (x - mean(x)) / sd(x),    \n               y_z = (y - mean(y)) / sd(y))\n```\n:::\n\n\n\n\n\nNow you can repeat the covariance calculation, but this time with the standardized variables `x_z` and `y_z` instead of `x` and `y`.\nHere we won't repeat the steps, but instead use the built in `cov()` function with the standardized variables.\nWe'll also calculate the correlation of `x` and `y` using the `cor()` function, so that you can see that it works.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncov(d$x_z, d$y_z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(d$x, d$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### First calculate covariance, then standardize it\n\nThe other way to calculate the correlation is to first calculate the covariance, and then standardize it.\nFor this we also need to know the `variance` of both `x` and `y`.\nLuckily, you already know how to calculate the variance, because this is the same as calculating the covariance of a variable with itself!\nWe heartily invite you to try this yourself, but here we'll just let R take care of the covariances for us.\nFor this we again use the `cov` function, but this time we give it a `tibble` as input.\nR will then return the covariance matrix for all variables in the `tibble`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd |>\n  select(x, y) |>\n  cov()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      x    y\nx 250.0 22.5\ny  22.5  2.5\n```\n\n\n:::\n:::\n\n\n\n\n\nHere we see four values:\n\n* The covariance of `x` with `x` (the variance of `x`), which is `250`.\n* The covariance of `y` with `y` (the variance of `y`), which is `2.5`.\n* The covariance of `x` with `y`, which we already know is `22.5`.\n* The covariance of `y` with `x`, which is the same as the covariance of `x` with `y`, because the covariance is symmetric.\n\nGiven this information, the correlation between `x` and `y` can be calculated as:\n\n$$ r = \\frac{cov(X, Y)}{S_X S_Y} $$\n\nWhere $S_X$ is the standard deviation of $X$, which you get by taking the square root of the variance.\n$$ S_X = \\sqrt{var(X)} $$\n\nSo the calculation is:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncov_xy = 22.5\nSx = sqrt(250)\nSy = sqrt(2.5)\n\ncov_xy / (Sx * Sy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9\n```\n\n\n:::\n:::\n\n\n\n\n\nWhich is the same as the correlation we calculated before!\n",
    "supporting": [
      "covariance-and-correlation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}