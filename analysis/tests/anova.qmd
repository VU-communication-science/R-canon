---
title: ANOVA
summary: Analysis of variance
format:
  html:
    df-print: paged
---


# What is an ANOVA?

ANOVA stands for **Analysis of Variance**, which can refer to a number of different statistical tests that are used to compare means between two or more groups.[^ttest]
It is a commonly used test in experimental research, where the key independent variable is usually categorical (e.g., treatment groups, control group).
There are different types of ANOVA to cover a wide range of research designs.
The most common ones are:

* **One-way ANOVA**. 
  * **Purpose**. Compare means *between-subjects* in different groups.[^independent_samples] 
  * **Example**. We want to know how the design of a health care robot affects how *comfortable* people feel about interacting with the robot. To test this we divide participants into three groups, that are shown three different designs ([Alice, Nao](https://vu.nl/nl/onderzoek/meer-over/sociale-robots-voor-de-samenleving-mediapsychologie), and RoboCop). They then answer multiple questions based on which we measure a *comfort rating* [scale](../techniques/scale-construction.qmd). We can now use One-way ANOVA to compare the mean comfort rating between the three groups.
* **Two-way ANOVA**. 
  * **Purpose**. Compare means *between-subjects* in different groups, for two independent variables. 
  * **Example**. In addition to comparing three different designs, we could also compare between using a *male* or *female* voice. We can then divide participants over six groups (3 designs * 2 voices), and use two-way ANOVA to test whether the design and voice have an effect on the perceived attractiveness, and whether there is an **interaction** between the two.
* **Repeated measures ANOVA**. 
  * **Purpose**. Compare means *within-subjects* measured at different timepoints.[^repeated_measures] 
  * **Example**. Instead of the self-reporting comfort rating, we could measure how people react to interacting with a health care robot by measuring their *heart rate*. We could then measure the *heart rate* of participants *before*, *during*, and *after* interacting with the robot. We can then use repeated measures ANOVA to compare the *heart rate* at each stage.
* **Mixed-design ANOVA**.
  * **Purpose**. Combine *between-subjects* and *within-subjects* factors. 
  * **Example**. This allows us to measure the effect of the design (one-way anova example) on the change in *heart rate* (repeated measures example). We divide participants into three groups that are shown the three different designs, and measure the *heart rate* of participants *before*, *during*, and *after* interacting with the robot. We can then use mixed-design ANOVA to test the effect of the design on the change in *heart rate*.


[^ttest]: If you are familiar with the t-test, you can think of ANOVA as a generalization of the t-test, which can only compare two groups.

[^independent_samples]: This is similar to an independent samples t-test, but can be used for more than two groups.

[^repeated_measures]: This is similar to a paired samples t-test, but can be used for more than two groups. This is primarily used for within-subjects designs, where the same participants are measured multiple times. 


<!-- # How does it work

Underneath the hood, ANOVA is a linear model just like [regression analysis](../tests/regression.qmd).
If you have not yet read the regression tutorial, you can skip this section, and focus first on how to use ANOVA in practice.

You can think of ANOVA as a special case of regression where the independent variables are categorical.
In the regression tutorial we showed you how you can use categorical independent variables in a regression model using dummy variables.
You might recall that it's not straightforward to compare all of the groups, or to test overall whether there is a difference between the groups.
ANOVA is a more specialized tool for this purpose.

To understand how ANOVA is *different* from *regular regression*, you need to understand two concepts.[^not_different]

[^not_different]: We emphasize *different* and *regular regression*, because technically ANOVA is still just a type of regression. By different we here refer to how ANOVA and regression are most commonly used in our field.

* **Contrast coding**. In regression we usually use **dummy coding** for categorical variables, which compares each group to a single reference group. But we can also use **effect coding** to compare each group to the *grand mean* (the mean of all groups). 
* **Sum of squares**. In a linear model we use sum of squares to assess how much variance is explained by the model. ANOVA allows using different types of sum of squares (Type I, II, III) for different purposes. In most cases researchers use Type III sums of squares (which is the default in popular statistics software like SPSS).



In the social sciences, when researchers use ANOVA, they usually use Type III sums of squares and effect coding. In popular statistics software like SPSS, this is also the default approach.
In this tutorial we will also stick to this default.
But as you'll see in the code, we do need to specify ourselves that we want to use Type II sums of squares and effect coding (specifically we'll use Helmert coding). -->


# How to use it

We'll use the `afex` and `emmeans` packages to perform ANOVA tests and compare means, and we'll use the `sjPlot` package to visualize the results.

```{r, message=F}
library(afex)
library(emmeans)
library(sjPlot)
```

For our examples we'll use our [Practice data](../../data-management/index.qmd#practice-data).
In this data have a (fictional) experiment where we study the effect of popular media on people's trust in journalists.
Specifically, we're using the following variables:

* **id**. A unique identifier for each participant.
* **experiment_group**. The group that participants were assigned to. Each group viewed a different movie that was either *neutral* (control), *positive*, or *negative* about journalism.
* **np_subscription**. Whether participants have a subscription to a national newspaper, with values *yes* or *no*.
* **trust_t1** and **trust_t2**. The trust in journalists, measured before (t1) and after (t2) watching a movie about journalism.

The **experiment_group** and **np_subscription** variables are our independent variable. To use these in the ANOVA, we'll explicitly convert them to factors, to indicate that they are categorical variables.

```{r, message=F}
library(tidyverse)
d <- read_csv("https://tinyurl.com/R-practice-data") |>
        mutate(experiment_group = as.factor(experiment_group),
               np_subscription = as.factor(np_subscription)) |>
        select(id, experiment_group, np_subscription, trust_t1, trust_t2)
d
```

## One-way ANOVA

In one-way ANOVA we compare the means of a dependent variable between two or more groups in a single independent variable.
We can use this to test the main question of our experiment: whether the movie (*experimental_group*) has an effect on the trust in journalists (*trust_t2*).[^trust_t2]

[^trust_t2]: We're using the trust score *after* watching the movie. It is *ok* to ignore the trust score before watching the movie, because we've randomly assigned participants to the different groups. This means that the trust score before watching the movie should be the same in each group. However, as we'll show below, we could also use a repeated measures ANOVA to compare the trust score before and after watching the movie.

We use the `aov_car` function from the `afex` package to fit the ANOVA model.
The formula that we use in this function is, as usual, `dependent_variable ~ independent_variable`.
However, we also need to specify the unique user id (`id`) using the `Error` function.
This way we explicitly clarify that each row in the data belongs to a unique participant in the study, which prevents you from mixing up between-subjects and within-subjects effects (more on this in the *repeated measures* section)
So the full formula is `dependent_variable ~ independent_variable + Error(id)`.

```{r, message=F}
m = aov_car(trust_t2 ~ experiment_group + Error(id), data=d)
m
```

```{r, echo=F, results=F}
m$anova_table$`num Df`[1]
num_df = m$anova_table$`num Df`[1]
den_df = m$anova_table$`den Df`[1]
f = m$anova_table$F[1] |> round(2)
```

When we print the output of the `aov_car` function, we get the main results of the ANOVA test.
In this one-way ANOVA we have a single independent variable, which is the `experiment_group`.
The output shows us the results of the F-test ($F_{`r num_df`, `r den_df`} = `r f`, p < 0.001$) which tells us that the difference between the groups is **significant**.
In other words, the movie that participants watched had a significant effect on their trust in journalists.

We also get an $eta^2$ (eta squared) value in the `ges` column (generalized eta squared[^ges]),
This is a measure of **effect size** that tells us how much variance in the dependent variable is explained by the independent variable (similar to the $R^2$ value in regression).

[^ges]: The generalized $eta2$ is a generalization of the (partial) $eta2$ value that is often reported in ANOVA output. It was proposed by @olejnik03 because regular partial $eta2$ values can be misleading when comparing between studies with different designs. Specifically, it allows taking into account whether factors in the model are *experimentally manipulated* or *observed*. In the **When factors are observed** subsection below we show how to specify this in the `aov_car` function.

Inside of the output of the `aov_car` function (which we named `m`) we also have the linear model (`lm`) that was fitted to the data, and the ANOVA table (`Anova`) that shows the results of the F-test.

```{r}
m$lm
m$Anova
```

::: {.callout-note title="Comparing between groups" collapse="true"}

The $eta^2$ and F-test only tell us that there is a difference between the groups, but not *where* the difference is.
To compare bewteen the groups, we can first of all look at their means.
For this we'll use the `emmeans` function from the `emmeans` package.

```{r}
means = emmeans(m, "experiment_group")
means
```

Now we can see that the lowest trust score is in the *negative* group, and the highest in the *positive* group.
However, we do not yet know whether the diffences between all the groups are significant.
It could be that the *positive* group is significantly higher than the *negative* group, but not significantly higher than the *control* group.
To test this we can use the `pairs` function to get the pairwise comparisons for the means we just computed.

```{r}
pairs(means)
```

Here we see all possible combinations of groups.
The **control - negative** (control *minus* negative) row tells us how much the trust score in the control group is higher than in the negative group, and whether this difference is significant.

Finally, we can visualize the results.
`afex` has a built-in plot function (afex_plot), but throughout this book we often use the flexible `plot_model` function from the `sjPlot` package, and we can use this here as well!
We can get the linear model from the `aov_car` output using `$lm`, and then use the `plot_model` function to visualize the results.

```{r, fig.height=3}
plot_model(m$lm, type='pred', terms='experiment_group')
```
::: 

### When factors are *observed*

In the previous example our independent variable was *experimentally manipulated*: we randomly assigned participants to the three groups.
However, in some cases we might have an independent variable that is *observed*, meaning that we did not manipulate it, but only *observed* a value that was already there.
This is the case for variables like *age* and *gender*, and in our case also for *np_subscribed* (whether participants have a newspaper subscription).

When factors are observed, we need to correct the $eta^2$ value to get more reliable effect sizes.
The `afex` package does this automatically for us by using the generalized $eta^2$ value (`ges` column in the output).
However, we do need to tell it when a factor is observed, using the `observed` argument in the `aov_car` function.

```{r, message=F}
aov_car(trust_t2 ~ np_subscription + Error(id), observed='np_subscription', data=d)
```

Long story short: **when you have an observed factor, make sure to specify** it in the `aov_car` function using the `observed` argument.


## Two-way ANOVA

In a two-way ANOVA we compare the means of a dependent variable between two or more groups in two independent variables.
To demonstrate this we'll use the `np_subscription` variable as a second independent variable.

The formula for a two-way ANOVA is `dependent_variable ~ independent_variable_1*independent_variable_2 + Error(id)`.
The `*` symbol is a shorthand for including both the main effects and the interaction effect between the two independent variables.
Note that we also again specify that `np_subscription` is an observed factor.

```{r, message=F}
m = aov_car(trust_t2 ~ experiment_group*np_subscription + Error(id), 
            observed='np_subscription', data=d)
```

Now our output shows three F-tests: one for the main effect of `experiment_group`, one for the main effect of `np_subscription`, and one for the interaction effect between the two. We also get three $eta^2$ values, one for each effect, which tell us how much variance is explained by each effect.

::: {.callout-note title="Comparing between groups" collapse="true"}

We can again use the `emmeans` function to get the means for each group.
Let's visualize the results first to get a better idea of how the two independent variables interact to affect the trust in journalists.

```{r, fig.height=3}
plot_model(m$lm, type='pred', terms=c('experiment_group', 'np_subscription'))
```

Here we see that the effect of `np_subscription` (having a newspaper subscription) mostly matters for the *negative* group.
It seems that overall people that watched a *negative* movie have a lower trust in journalists, but this is mostly true for people that do not have a newspaper subscription.
In other words, people that have a newspaper subscription might not be as affected by the negative movie.

We can now use the `emmeans` function to test these differences.
To see how the effect of `experimental_group` is different for people that do or do not have a newspaper subscription, we can look at means of the `experiment_group` variable **conditional on** (`by`) the `np_subscription` variable.

```{r}
means = emmeans(m, 'experiment_group', by='np_subscription')
means
pairs(means)
```

We can now compare how the movie affects the trust in journalists, while taking into account how this is conditional on whether people have a newspaper subscription.

Likewise, we could also compare how the newspaper subscription affects the trust in journalists, while taking into account how this is conditional on the movie that people watched.

```{r, results=F, message=F}
means = emmeans(m, 'np_subscription', by='experiment_group')
means
pairs(means)
```

And finally, we could also compare between ALL the groups. 

```{r, results=F, message=F}
means = emmeans(m, c('experiment_group', 'np_subscription'))
means
pairs(means)

iris$id = 1:nrow(iris)
ds = iris[1:130,]
m = aov_car(Sepal.Length ~ Species + Error(id), data=ds)
table(ds$Species)

ds |>
    group_by(Species) |>
    summarise(mean = mean(Sepal.Length), sd = sd(Sepal.Length), se = sd/sqrt(n()))
emmeans(m, 'Species')


```
:::

# Conditions and assumptions

ANOVA is a parametric test, which means that it makes assumptions about the data.
If these assumptions are violated, the results of the ANOVA can be unreliable.
The most important assumptions are:

1. **Normality**. The dependent variable should be normally distributed in each group.
2. **Homogeneity of variance**. The variance of the dependent variable should (approximately) be equal in each group.
3. **Independence**. Observations should be independent of each other. 

Here we will only discuss the assumption of **homogeneity of variance**, because it is more specific to ANOVA.
For the other assumptions, which are more general to linear models, we refer to the [regression tutorial](../tests/linear-regression.qmd).
If you have not yet learned about regression, you can ignore the details of these other assumptions for now.

### Homogeneity of variance

Homogeneity of variance means that the variance of the dependent variable should be (approximately) equal in each group.
In our one-way ANOVA example, this means that the variance of the trust score should be equal in the *control*, *positive*, and *negative* groups.

We can test this with the Levene's test, which is a test for homogeneity of variance.
The null hypothesis of the Levene's test is that the variance is equal in each group.
If the p-value of the test is less than 0.05, we reject the null hypothesis and conclude that the variance is not equal in each group.

To perform the Levene's test we can use the `leveneTest` function from the `car` package.
To test whether the variance of the trust score (dependent variable) is equal in each group of the independent variable, we use the formula `dependent_variable ~ independent_variable`.

```{r, message=F}
library(car)
leveneTest(trust_t2 ~ experiment_group, data=d)
```
