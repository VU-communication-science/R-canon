---
title: "Multiple regression"
subtitle: "Controlling for other variables"
format:
  html:
    df-print: paged
---


# What is multiple regression?

Multiple regression means that we are using more than one predictor variable to predict the dependent variable.
In practice, it is very similar to simple linear regression, and if you already know how to use and report simple linear regression, you can easily extend this to multiple regression. 
If you are not yet familiar with simple linear regression, make sure to check out the [tutorial on linear regression](../tests/linear-regression.qmd) first.

Multiple regression is a critical tool in the social sciences, because it allows us to control for confounding variables.
As explained in the section on [correlation](../tests/correlation.qmd), we need to be careful when interpreting the correlation between two variables, because it might be a **spurious correlation**.
The same is true for the effects in a regression model.
It is possible (and common) that the effect of the independent variable on the dependent variable is not because of an actual causal relation. 
Instead, it could be due to a third variable that influences both the independent and dependent variable.
This third variable is then called a **confounding variable**, and the effect that we observe between the independent and dependent variable is a **spurious effect**.

*Multiple* regression allows us to control for these confounding variables by including *multiple* independent variables in the model.
When we do, the model estimates the effect of each independent variable on the dependent variable *while controlling for the other variables*.

# How to use

To use multiple regression in R, you can use the `lm()` function, just like in simple linear regression.
We will again be using our practice data, which contains the variables `trust_t1`, `np_subscription`, and `age`.

```{r, message=F}
library(tidyverse)
library(sjPlot)

## read and clean the practice data
d <- read_csv("https://tinyurl.com/R-practice-data") |>
        mutate(age = if_else(age > 100, 2024 - age, age))

m1 <- lm(trust_t1 ~ np_subscription, data = d)
m2 <- lm(trust_t1 ~ np_subscription + age, data = d)
tab_model(m1, m2)
```

Let's use the same example data as in the linear regression tutorial for using a `dummy` variable, where we looked at the effect of `np_subscription` (yes/no) on `trust_t1`. 
But this time, we also run a second model where we also add the `age` of the participants as a control variable.
<!-- Demographic variables like `age`, `gender` and `education` are often used as control variables, because they are known to influence many other variables, making them likely to lead to spurious effects. -->

When running multiple regression, it is good practice to report the results of multiple models side by side. 
This way you can see what happens to the effects when you control for other variables.
With the `tab_model()` function from the `sjPlot` package, you can pass multiple models to the function and it will show you the results side by side.


In the first model, we see that people that have a subscription to a newspaper have a higher trust in the news media compared to people that do not have a subscription ($b = 0.37$, p < 0.001).
However, in the second model, where we control for age, this effect is no longer significant ($b = -0.04$, p = 0.612).
This suggests that the effect of `np_subscription` on `trust_t1` was spurious, and that the real reason for the difference in trust between subscribers and non-subscribers is the age of the participants.
That is, older people are more likely to have a newspaper subscription, and older people also have a higher trust in the news media.

Being able to control for confounding variables enables us to better explore possible [causal relationships](../concepts/causality.qmd) between variables.
Based on the first model, we might have concluded that having a newspaper subscription causes people to trust the news media more.
If we were a newspaper, this finding might have led us to invest in subscription campaigns to increase trust in the news media.
However, our second model indicates that this strategy would *probably*[^1] not be effective.

[^1]: We say *probably*, because we cannot say with certainty that a newspaper subscription really has no effect.
The only thing we can say is that based on this data, we do not find evidence for this effect.
But this *is* already a huge win, because it prevents us from making bad decisions based on a spurious effect.

