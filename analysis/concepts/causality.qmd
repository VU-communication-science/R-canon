---
title: Causality
subtitle: How to find evidence for causal relations?
order: 3
---


![xkcd: correlation](https://imgs.xkcd.com/comics/correlation.png)


# Testing causal relations

In communication science we are often concerned with **causal relations**. 
Consider the following two examples:

- When news media focus heavily on certain issues, it enhances the public's perception of their importance [@mccombs72].
- More screen time among children and adolescents is associated with lower psychological well-being [@twenge18].

Research into such causal relations is important, because by understanding causal mechanisms, we can develop strategies to change the outcomes for the better.
If more screen time causes lower psychological well-being, we should advice parents to limit children's screen time.

In order to determine whether we should really incur the wrath of our children by taking away their smartphones, we need to test our theory with empirical data.
As usual, we can [derive hypotheses](../concepts/hypotheses.qmd) that predict relationships between variables, and then test these hypotheses with **statistical methods**.
However, when testing causal relations, we need to particularly careful!

A common mistake is to assume that a correlation between two variables implies a causal relationship.
Even if we find strong evidence that people that have more screen time also have lower psychological well-being, this does not prove that screen time causes lower well-being!
There is a famous saying in statistics: **correlation does not imply causation**.
In this tutorial you will learn why this is the case, and how to deal with it.


# Why correlation does not imply causation

**Causation** implies a cause-effect relationship, where a change in one variable (the cause) leads to a change in the other (the effect). 
The cause does not need to be the *only* cause of the effect (there are many things that affect well-being), nor does it *always* need to lead to the effect (some people with high screen time will be happier than other with low screen time).
It is enough that the cause increases the likelihood of the effect.
If we were to somehow manipulate the cause, we would expect the likelihood of the effect to change.

[Correlation](../concepts/covariance-and-correlation.qmd), on the other hand, only indicates an association or relationship between two variables.
It makes sense why people can confuse this for a causal relationship.
If we see that people that that are often on their phone are overall less happy, it is easy to assume that the phone is the cause of their unhappiness.
But in order to establish whether a correlation is due to a causal relationship, we need address three issues:

* **Confounding**: A correlation could be due to a third variable that causes both of them to change. 
    Both screen time and psychological well-being could for instance be influenced by parental involvement.
    If the relation between two variables is not because they are causally related, but because they are both influenced by a third variable, we call this a **spurious correlation**.
    The third variable that causes the correlation is called a **confounding variable**.
* **Directionality**: A correlation does not tell us which variable causes the other.
    It could be that more screen time causes lower psychological well-being, but it could also be that children with lower psychological well-being spend more time on screens.
    If this is the case, taking away their phone would not help!
* **Coincidence**: A correlation is also **spurious** if it is just a coincidence.
    This is something we can address with statistical tests, but it bears keeping in mind. (See the box below for some famous examples of spurious correlations.)
    
::: {.callout-tip title="Famous spurious correlations" collapse="true"}
A [famous example](http://www.brixtonhealth.com/storksBabies.pdf) is that across European countries the number of storks is quite strongly correlated with the number of newborn babies ($\rho = 0.62$). A naive interpretation would be that this provides evidence for the folk theory that storks deliver babies. The real reason in this case is due to a confounding variable: the size of the country. Larger countries simply have more storks and more babies.

There is also a website called [Spurious Correlations](https://www.tylervigen.com/spurious-correlations), that is dedicated to finding coincidental spurious correlations, such as the correlation between the number of people who drowned by falling into a pool and the number of films Nicolas Cage appeared in.
:::


# How to establish causation

So how can we better establish whether a cause-effect relationship exists between our variables of interest?
There is no easy answer for this, and the appropriate methodology is a whole field of research in itself [see @pearl09].
But there are several general strategies that we can use to build evidence for causation.

## Theoretical foundation

First of all, it is critical to have a solid **theoretical foundation** for the relationship.
We need to have a good reason to believe that one variable causes the other.

A theoretical foundation can also help address the issue of **directionality**.
In their study on screen time and psychological well-being, Twenge and Campbell emphasized that based on their (observational) data "it is not possible to determine if screen time leads to low well-being, low well-being leads to screen time, or both" [@twenge18, p. 281].
So in order to build their argument for a causal relationship, they discussed literature that supports their view that screen time is the cause of lower well-being, and not the other way around.

It is often the case that we cannot determine causality from a single study, but need to build a body of evidence from multiple studies that point in the same direction.
An experiment might be able to establish causality, but only for a very specific context and short term effects.
An observational study might be able to find correlations that are consistent across many different contexts and time periods, but it cannot establish causality.
To build theory on complicated issues such as the relationship between screen time and well-being, we need to combine both types of studies.

## Randomized controlled experiments

The gold standard for establishing causation is the **randomized controlled experiment**, in which the researcher *manipulates the cause* and observes the effect, while keeping all other variables constant.
In order to manipulate the cause, the researcher creates different experimental conditions.
The classic example comes from the field of medicine: you give some participants a medicine you want to test, where others get a placebo (i.e. a fake medicine that only looks the same).
The people that got the real medicine are then the *treatment group*, and the people that got the placebo are the *control group*
To test if the medicine works, you compare the treatment group to the control group.[^1]

[^1]: A similar example from communication science could be that you want to test the effictiveness of a new persuasion strategy.
You could then show the treatment group a persuasive message that uses the new strategy, and the control group a message that doesn't. 

The experimental design helps to adress both **confounding** and **directionality**.

* By randomly assigning people to the treatment or control group, the people in both groups are *statistically identical*. If the randomization is done correctly, any possible confounding variables are equally distributed between the two groups, and so any difference in the outcome can be attributed to the treatment. 
* By comparing the treatment group to the control group, you can account for confounding variables that have to do with the process of appyling the treatment. A well known example of this is the *placebo effect*, where people feel better just because they *think* they're taking a medicine (control group), and not because of the actual medicine (treatment group). If the medicine works, the treatment group should see a stronger effect than the control group. 

This ability to eliminate the influence of confounders makes experiments a powerful tool for establishing causation.
However, in the field of communication science it is often not possible (or ethical) to conduct valid experiments.
For many of the causes that we are interested in, it is simply not possible to manipulate it in a controlled setting that is still sufficiently similar to the real world.

## Controlling for confounders

If we cannot conduct an experiment, we can to some extend control for confounding variables using **statistical methods**.
This is not as powerful as an experiment, but it does allow us to establish some level of evidence for causation from observational data.
In fact, many well supported causal theories in communication science have only been supported this way, such as the relationship between media coverage and public opinion [@mccombs72].
And even common knowledge like "smoking causes cancer", that is the foundation for anti-smoking policies, relies heavily on evidence from these types of observational studies.
Given that many communication science theories cannot be tested with experiments, being able to gather evidence for causal relations from observational data is an essential part of the communication scientist's toolkit.

The trick behind statistically controlling for confounders lies in **multivariate analysis** (i.e. analyzing more than two variables at the same time).
If we are worried that a correlation between a **dependent variable** and **independent variable** is due to a third variable, we can add this **confounding variable** to the analysis.
Using techniques like **multiple regression**, we can then measure the effect of the independent variable on the dependent variable while holding the confounding variable constant.
We also call this **controlling for** the confounder.

Note that this is different from experiments, where we can controll for all possible confounders through randomization.
In observational studies, we can only control for the variables that we have measured.
This puts an even greater burden on having a solid theoretical foundation for the relationships we test.


<!-- An an example, consider the *agenda-setting theory* [@mccombs72], which posits that the media influence the public's perception of the importance of issues.
Initially, the primary evidence for this theory came from a study that showed a correlation between the amount of media coverage of an issue and the public's perception of its importance.
At the time, news media were one of the few sources of information for the public, so *on theoretical grounds* it was reasonable to assume that the media were the cause of the public's perception.
But today, with the rise of social media and other information sources, the relationship between media coverage and public opinion is more complex.
To test the theory today, we would need to control for other sources of information, such as social media, to see if the relationship between media coverage and public opinion still holds.

This also emphasizes that statistics are never a substitute for theory.
Statistics allow us to build stronger empirical evidence for our theories, but we need theory to guide us in what to measure and how to interpret the results. -->
